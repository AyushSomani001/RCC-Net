{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#info\n",
    "#author: Yanlin Qian(yanlin.qian@tut.fi)\n",
    "#Main script for performing temporal color constancy system using RCC-Net in paper:\n",
    "#Yanlin Qian, Ke Chen, Jarno Nikkanen, Joni Kamarainen, Jiri Matas\n",
    "#Recurrent Color Constancy.ICCV, 2017.\n",
    "\n",
    "#settting\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "keras_path='/usr/local/lib/python2.7/dist-packages'\n",
    "sys.path.insert(0,keras_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11346, 3)\n",
      "(1, 11346)\n"
     ]
    }
   ],
   "source": [
    "#load the whole dataset greyball\n",
    "import scipy.io as sio\n",
    "path_sfucolor='/home/qian2/qian2_old/AWB/sfugreyball/'\n",
    "\n",
    "#precrop images into this folder\n",
    "path_sfucolor_all=os.path.join(path_sfucolor,'nonlinear_sfugreyball_all_crop/');\n",
    "# path_sfucolor_gt=os.path.join(path_sfucolor,'sfugreyball_gt/');\n",
    "\n",
    "#load groundtruth and image indexes, this mat file is provided.\n",
    "path_sfucolor_mat=os.path.join(path_sfucolor,'nonlinear_index&gt.mat');\n",
    "mat=sio.loadmat(path_sfucolor_mat)\n",
    "matrix_gt_index=mat['matrix_gt_index']\n",
    "matrix_illum=mat['real_rgb'];\n",
    "print matrix_illum.shape\n",
    "print matrix_gt_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11346, 4096)\n"
     ]
    }
   ],
   "source": [
    "#load the deep feature of the whole dataset\n",
    "path_fcn='/home/qian2/qian2_old/fcn'\n",
    "\n",
    "#name_feature='deepfeature/greyball_all_vggfc6.mat'\n",
    "name_feature='deepfeature/greyball_all_vggfc6_nonlinear_crop.npy'\n",
    "path_feature=os.path.join(path_fcn,name_feature)\n",
    "matrix_feature=np.load(path_feature)\n",
    "print matrix_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the temporal dataset (index of frames of each video)\n",
    "path_temporal='/home/qian2/qian2_old/temporalcolorconstancy/'\n",
    "name_temporal='index_temporal_greyball_thres0.mat';\n",
    "path_temporal=os.path.join(path_temporal,name_temporal);\n",
    "mat=sio.loadmat(path_temporal)\n",
    "matrix_index=mat['indexs']\n",
    "matrix_sequencenum=mat['sequence_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get absolute indexs\n",
    "matrix_allindex=np.array(matrix_index,copy='True')\n",
    "for i in np.arange(matrix_index.shape[1]):\n",
    "    matrix_allindex[0][i]=np.arange(0,matrix_sequencenum[i],1)+np.sum(matrix_sequencenum[0:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15)\n",
      "(1, 15)\n",
      "[   0    1    2 ..., 1270 1271 1272]\n"
     ]
    }
   ],
   "source": [
    "print matrix_index.shape\n",
    "print matrix_allindex.shape\n",
    "print matrix_allindex[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del matrix_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Reshape,Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import SGD\n",
    "from keras.objectives import cosine_proximity\n",
    "from keras.objectives import mean_squared_error\n",
    "from keras.objectives import mean_squared_logarithmic_error\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.core import Merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def angular_loss(y_true,y_pred):\n",
    "    y_true=K.l2_normalize(y_true,axis=-1)\n",
    "    y_pred=K.l2_normalize(y_pred,axis=-1)\n",
    "    loss=1-(K.sum(y_true*y_pred,axis=-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Reshape((1,32,32,3),input_shape=(32,32,3)))           \n",
    "model2 = Sequential()\n",
    "model2.add(Reshape((1,32,32,3),input_shape=(32,32,3)))\n",
    "model3 = Sequential()\n",
    "model3.add(Reshape((1,32,32,3),input_shape=(32,32,3)))           \n",
    "\n",
    "merged=Merge([model1,model2,model3],mode='concat',concat_axis=1) #(2,3,224,224)\n",
    "#merged=Concatenate([model1,model2,model3],axis=1) #later we found 3-frame-long simulated sequence is just enough\n",
    "model_fake = Sequential()\n",
    "model_fake.add(merged)\n",
    "#     model_fake.add(TimeDistributed(ZeroPadding2D((1,1),input_shape=(3,32,32))))\n",
    "model_fake.add(TimeDistributed(Convolution2D(240, 1, 1, activation='sigmoid')))\n",
    "model_fake.add(TimeDistributed(MaxPooling2D((8,8), strides=(8,8))))\n",
    "model_fake.add(TimeDistributed(Flatten()))\n",
    "#     model_fake.add(TimeDistributed(Dense(4096, activation='relu')))#(samples,max_caption_len,4096\n",
    "model_fake.add(LSTM(128,activation='sigmoid',inner_activation='sigmoid',input_shape=(None,3840)))\n",
    "\n",
    "model_real = Sequential()\n",
    "model_real.add(LSTM(output_dim=128,input_dim=4096,input_length=5,activation='sigmoid', inner_activation='sigmoid'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([model_fake,model_real],mode='concat',concat_axis=1))\n",
    "#model.add(Concatenate([model_fake,model_real],axis=-1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,input_shape=(128,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(3,input_shape=(64,)))\n",
    "model.add(Activation(\"linear\"))  \n",
    "\n",
    "model.compile(loss=angular_loss, optimizer=\"rmsprop\")\n",
    "Wsave_initial = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#measure the angular error\n",
    "def get_angular_error(predicted,testlabel):\n",
    "    norm_a=np.linalg.norm(predicted,axis=1)\n",
    "    norm_b=np.linalg.norm(testlabel,axis=1)\n",
    "    norm_ab=np.multiply(norm_a,norm_b)\n",
    "    product_ab=np.multiply(predicted,testlabel)\n",
    "    product_ab=np.sum(product_ab,axis=1)\n",
    "    divide_ab=np.divide(product_ab,norm_ab)\n",
    "    angu_error_ab=np.arccos(divide_ab)\n",
    "    \n",
    "    print np.min(angu_error_ab)*180/np.pi\n",
    "    print np.mean(angu_error_ab)*180/np.pi\n",
    "    print np.max(angu_error_ab)*180/np.pi\n",
    "    print np.median(angu_error_ab)*180/np.pi\n",
    "    return angu_error_ab\n",
    "\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
    "from mimic import MimickingGenerator\n",
    "train_datagen=MimickingGenerator(rotation_range=5,zoom_range=0.5,width_shift_range=0.1,height_shift_range=0.1)\n",
    "test_datagen=ImageDataGenerator(rescale=1.0);\n",
    "\n",
    "def readimg_greyball(path_sfucolor_all,img_name):\n",
    "    img_name=img_name+'.jpg'\n",
    "    file_jpg=os.path.join(path_sfucolor_all,img_name)\n",
    "    img=load_img(file_jpg)\n",
    "    img=img.resize((32,32),Image.NEAREST)\n",
    "    x=img_to_array(img)\n",
    "    return x\n",
    "\n",
    "def getmimic(indexs_img,time_range,matrix_gt_index,path_sfucolor_all,train_datagen):\n",
    "    nb_samples=indexs_img.shape[0]\n",
    "    X_test=np.zeros((nb_samples,time_range,32,32,3))\n",
    "    for i in range(nb_samples):\n",
    "        index=indexs_img[i]\n",
    "        img_name=matrix_gt_index[0,index][0]\n",
    "        x=readimg_greyball(path_sfucolor_all,img_name)\n",
    "        x=x.reshape((1,)+x.shape) #(1,3,32,32)\n",
    "        trueimg=x\n",
    "        for number_merge in range(time_range):\n",
    "            for batch in train_datagen.flow(x,batch_size=1):\n",
    "                break\n",
    "            X_test[i,number_merge,:,:,:]=batch[0,:,:,:]\n",
    "        X_test[i,-1,:,:,:]=trueimg\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_testing:0\n",
      "(1273, 5, 4096) (1273, 3, 32, 32, 3) (1273, 3)\n",
      "(10073, 5, 4096) (10073, 3, 32, 32, 3) (10073, 3)\n",
      "Train on 9972 samples, validate on 101 samples\n",
      "Epoch 1/80\n",
      "9972/9972 [==============================] - 11s - loss: 0.0289 - val_loss: 0.0036\n",
      "Epoch 2/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0052 - val_loss: 0.0148\n",
      "Epoch 3/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0039 - val_loss: 0.0072\n",
      "Epoch 4/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 5/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 6/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 7/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 8/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 9/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 10/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 11/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 12/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 13/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 14/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 15/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 16/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 17/80\n",
      "9972/9972 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 18/80\n",
      "9972/9972 [==============================] - 7s - loss: 9.7893e-04 - val_loss: 0.0025\n",
      "Epoch 19/80\n",
      "9972/9972 [==============================] - 7s - loss: 9.3401e-04 - val_loss: 0.0048\n",
      "Epoch 20/80\n",
      "9972/9972 [==============================] - 7s - loss: 9.0713e-04 - val_loss: 0.0040\n",
      "Epoch 21/80\n",
      "9972/9972 [==============================] - 7s - loss: 8.8239e-04 - val_loss: 0.0051\n",
      "Epoch 22/80\n",
      "9972/9972 [==============================] - 7s - loss: 8.3456e-04 - val_loss: 0.0050\n",
      "Epoch 23/80\n",
      "9972/9972 [==============================] - 7s - loss: 8.0273e-04 - val_loss: 0.0042\n",
      "Epoch 24/80\n",
      "9972/9972 [==============================] - 7s - loss: 7.5378e-04 - val_loss: 0.0026\n",
      "Epoch 25/80\n",
      "9972/9972 [==============================] - 7s - loss: 7.5374e-04 - val_loss: 0.0034\n",
      "Epoch 26/80\n",
      "9972/9972 [==============================] - 7s - loss: 7.1788e-04 - val_loss: 0.0062\n",
      "Epoch 27/80\n",
      "9972/9972 [==============================] - 7s - loss: 7.0235e-04 - val_loss: 0.0033\n",
      "Epoch 28/80\n",
      "9972/9972 [==============================] - 7s - loss: 6.9580e-04 - val_loss: 0.0045\n",
      "Epoch 29/80\n",
      "9972/9972 [==============================] - 7s - loss: 6.8608e-04 - val_loss: 0.0066\n",
      "Epoch 30/80\n",
      "9972/9972 [==============================] - 7s - loss: 6.6612e-04 - val_loss: 0.0037\n",
      "Epoch 31/80\n",
      "9972/9972 [==============================] - 7s - loss: 6.3964e-04 - val_loss: 0.0053\n",
      "Epoch 32/80\n",
      "9972/9972 [==============================] - 7s - loss: 6.1447e-04 - val_loss: 0.0042\n",
      "Epoch 33/80\n",
      "9972/9972 [==============================] - 7s - loss: 6.0429e-04 - val_loss: 0.0059\n",
      "Epoch 34/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.9579e-04 - val_loss: 0.0042\n",
      "Epoch 35/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.8835e-04 - val_loss: 0.0033\n",
      "Epoch 36/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.7591e-04 - val_loss: 0.0029\n",
      "Epoch 37/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.5567e-04 - val_loss: 0.0035\n",
      "Epoch 38/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.5327e-04 - val_loss: 0.0039\n",
      "Epoch 39/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.3062e-04 - val_loss: 0.0056\n",
      "Epoch 40/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.4334e-04 - val_loss: 0.0043\n",
      "Epoch 41/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.0309e-04 - val_loss: 0.0052\n",
      "Epoch 42/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.2228e-04 - val_loss: 0.0053\n",
      "Epoch 43/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.0003e-04 - val_loss: 0.0052\n",
      "Epoch 44/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.8663e-04 - val_loss: 0.0023\n",
      "Epoch 45/80\n",
      "9972/9972 [==============================] - 7s - loss: 5.0579e-04 - val_loss: 0.0053\n",
      "Epoch 46/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.6519e-04 - val_loss: 0.0056\n",
      "Epoch 47/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.6994e-04 - val_loss: 0.0029\n",
      "Epoch 48/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.6863e-04 - val_loss: 0.0036\n",
      "Epoch 49/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.5096e-04 - val_loss: 0.0054\n",
      "Epoch 50/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.5573e-04 - val_loss: 0.0025\n",
      "Epoch 51/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.4823e-04 - val_loss: 0.0048\n",
      "Epoch 52/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.3930e-04 - val_loss: 0.0036\n",
      "Epoch 53/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.2934e-04 - val_loss: 0.0053\n",
      "Epoch 54/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.1109e-04 - val_loss: 0.0057\n",
      "Epoch 55/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.1747e-04 - val_loss: 0.0049\n",
      "Epoch 56/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.0998e-04 - val_loss: 0.0046\n",
      "Epoch 57/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.1852e-04 - val_loss: 0.0052\n",
      "Epoch 58/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.9750e-04 - val_loss: 0.0037\n",
      "Epoch 59/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.9321e-04 - val_loss: 0.0042\n",
      "Epoch 60/80\n",
      "9972/9972 [==============================] - 7s - loss: 4.0759e-04 - val_loss: 0.0038\n",
      "Epoch 61/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.9490e-04 - val_loss: 0.0047\n",
      "Epoch 62/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.8444e-04 - val_loss: 0.0040\n",
      "Epoch 63/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.8184e-04 - val_loss: 0.0036\n",
      "Epoch 64/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.7295e-04 - val_loss: 0.0037\n",
      "Epoch 65/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.7175e-04 - val_loss: 0.0031\n",
      "Epoch 66/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.6368e-04 - val_loss: 0.0047\n",
      "Epoch 67/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.6192e-04 - val_loss: 0.0042\n",
      "Epoch 68/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.5197e-04 - val_loss: 0.0036\n",
      "Epoch 69/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.6079e-04 - val_loss: 0.0036\n",
      "Epoch 70/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.4772e-04 - val_loss: 0.0043\n",
      "Epoch 71/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.5890e-04 - val_loss: 0.0054\n",
      "Epoch 72/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.4562e-04 - val_loss: 0.0036\n",
      "Epoch 73/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.5158e-04 - val_loss: 0.0051\n",
      "Epoch 74/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.3544e-04 - val_loss: 0.0049\n",
      "Epoch 75/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.3556e-04 - val_loss: 0.0054\n",
      "Epoch 76/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.4358e-04 - val_loss: 0.0044\n",
      "Epoch 77/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.3293e-04 - val_loss: 0.0044\n",
      "Epoch 78/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.2452e-04 - val_loss: 0.0040\n",
      "Epoch 79/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.2070e-04 - val_loss: 0.0026\n",
      "Epoch 80/80\n",
      "9972/9972 [==============================] - 7s - loss: 3.2788e-04 - val_loss: 0.0038\n",
      "0.023567917319\n",
      "2.1510561038\n",
      "13.6107161574\n",
      "2.01569368234\n",
      "sequence_testing:1\n",
      "(952, 5, 4096) (952, 3, 32, 32, 3) (952, 3)\n",
      "(10394, 5, 4096) (10394, 3, 32, 32, 3) (10394, 3)\n",
      "Train on 10290 samples, validate on 104 samples\n",
      "Epoch 1/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0286 - val_loss: 0.0047\n",
      "Epoch 2/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 3/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0037 - val_loss: 0.0099\n",
      "Epoch 4/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 5/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 6/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 7/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 8/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 9/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 10/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 11/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 12/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 13/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 14/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 15/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 16/80\n",
      "10290/10290 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0063\n",
      "Epoch 17/80\n",
      "10290/10290 [==============================] - 7s - loss: 9.5046e-04 - val_loss: 0.0041\n",
      "Epoch 18/80\n",
      "10290/10290 [==============================] - 7s - loss: 9.4767e-04 - val_loss: 0.0039\n",
      "Epoch 19/80\n",
      "10290/10290 [==============================] - 7s - loss: 8.7141e-04 - val_loss: 0.0032\n",
      "Epoch 20/80\n",
      "10290/10290 [==============================] - 7s - loss: 8.1909e-04 - val_loss: 0.0045\n",
      "Epoch 21/80\n",
      "10290/10290 [==============================] - 7s - loss: 8.1123e-04 - val_loss: 0.0033\n",
      "Epoch 22/80\n",
      "10290/10290 [==============================] - 7s - loss: 8.0713e-04 - val_loss: 0.0049\n",
      "Epoch 23/80\n",
      "10290/10290 [==============================] - 7s - loss: 7.6514e-04 - val_loss: 0.0061\n",
      "Epoch 24/80\n",
      "10290/10290 [==============================] - 7s - loss: 7.5096e-04 - val_loss: 0.0055\n",
      "Epoch 25/80\n",
      "10290/10290 [==============================] - 7s - loss: 7.2670e-04 - val_loss: 0.0056\n",
      "Epoch 26/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.9494e-04 - val_loss: 0.0034\n",
      "Epoch 27/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.5688e-04 - val_loss: 0.0049\n",
      "Epoch 28/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.5263e-04 - val_loss: 0.0039\n",
      "Epoch 29/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.2649e-04 - val_loss: 0.0051\n",
      "Epoch 30/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.4490e-04 - val_loss: 0.0053\n",
      "Epoch 31/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.0435e-04 - val_loss: 0.0056\n",
      "Epoch 32/80\n",
      "10290/10290 [==============================] - 7s - loss: 6.1321e-04 - val_loss: 0.0052\n",
      "Epoch 33/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.8061e-04 - val_loss: 0.0038\n",
      "Epoch 34/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.6519e-04 - val_loss: 0.0035\n",
      "Epoch 35/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.4463e-04 - val_loss: 0.0042\n",
      "Epoch 36/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.3330e-04 - val_loss: 0.0040\n",
      "Epoch 37/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.3291e-04 - val_loss: 0.0052\n",
      "Epoch 38/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.2314e-04 - val_loss: 0.0045\n",
      "Epoch 39/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.1819e-04 - val_loss: 0.0062\n",
      "Epoch 40/80\n",
      "10290/10290 [==============================] - 7s - loss: 5.0208e-04 - val_loss: 0.0055\n",
      "Epoch 41/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.9307e-04 - val_loss: 0.0055\n",
      "Epoch 42/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.8482e-04 - val_loss: 0.0041\n",
      "Epoch 43/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.7366e-04 - val_loss: 0.0053\n",
      "Epoch 44/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.6506e-04 - val_loss: 0.0038\n",
      "Epoch 45/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.6104e-04 - val_loss: 0.0050\n",
      "Epoch 46/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.5250e-04 - val_loss: 0.0050\n",
      "Epoch 47/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.3504e-04 - val_loss: 0.0043\n",
      "Epoch 48/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.3784e-04 - val_loss: 0.0046\n",
      "Epoch 49/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.3169e-04 - val_loss: 0.0047\n",
      "Epoch 50/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.1772e-04 - val_loss: 0.0047\n",
      "Epoch 51/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.0209e-04 - val_loss: 0.0057\n",
      "Epoch 52/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.0746e-04 - val_loss: 0.0054\n",
      "Epoch 53/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.0602e-04 - val_loss: 0.0048\n",
      "Epoch 54/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.9629e-04 - val_loss: 0.0065\n",
      "Epoch 55/80\n",
      "10290/10290 [==============================] - 7s - loss: 4.0783e-04 - val_loss: 0.0042\n",
      "Epoch 56/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.8433e-04 - val_loss: 0.0049\n",
      "Epoch 57/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.7887e-04 - val_loss: 0.0047\n",
      "Epoch 58/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.6553e-04 - val_loss: 0.0057\n",
      "Epoch 59/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.7905e-04 - val_loss: 0.0067\n",
      "Epoch 60/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.7004e-04 - val_loss: 0.0075\n",
      "Epoch 61/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.5496e-04 - val_loss: 0.0061\n",
      "Epoch 62/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.6796e-04 - val_loss: 0.0050\n",
      "Epoch 63/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.5558e-04 - val_loss: 0.0057\n",
      "Epoch 64/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.4355e-04 - val_loss: 0.0051\n",
      "Epoch 65/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.4418e-04 - val_loss: 0.0043\n",
      "Epoch 66/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.4176e-04 - val_loss: 0.0052\n",
      "Epoch 67/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.3027e-04 - val_loss: 0.0068\n",
      "Epoch 68/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.3958e-04 - val_loss: 0.0043\n",
      "Epoch 69/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.2749e-04 - val_loss: 0.0055\n",
      "Epoch 70/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.3098e-04 - val_loss: 0.0055\n",
      "Epoch 71/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.2831e-04 - val_loss: 0.0038\n",
      "Epoch 72/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.1870e-04 - val_loss: 0.0049\n",
      "Epoch 73/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.1160e-04 - val_loss: 0.0074\n",
      "Epoch 74/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.0600e-04 - val_loss: 0.0059\n",
      "Epoch 75/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.2424e-04 - val_loss: 0.0053\n",
      "Epoch 76/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.0984e-04 - val_loss: 0.0048\n",
      "Epoch 77/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.0636e-04 - val_loss: 0.0052\n",
      "Epoch 78/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.0002e-04 - val_loss: 0.0055\n",
      "Epoch 79/80\n",
      "10290/10290 [==============================] - 7s - loss: 3.0324e-04 - val_loss: 0.0068\n",
      "Epoch 80/80\n",
      "10290/10290 [==============================] - 7s - loss: 2.8384e-04 - val_loss: 0.0056\n",
      "0.0491610957939\n",
      "2.9328399474\n",
      "12.7865054446\n",
      "2.11602301935\n",
      "sequence_testing:2\n",
      "(981, 5, 4096) (981, 3, 32, 32, 3) (981, 3)\n",
      "(10365, 5, 4096) (10365, 3, 32, 32, 3) (10365, 3)\n",
      "Train on 10261 samples, validate on 104 samples\n",
      "Epoch 1/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0278 - val_loss: 0.0131\n",
      "Epoch 2/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 3/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 4/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 5/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 6/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 7/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 8/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 9/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 10/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0075\n",
      "Epoch 11/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 12/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 13/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 14/80\n",
      "10261/10261 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 15/80\n",
      "10261/10261 [==============================] - 7s - loss: 9.8635e-04 - val_loss: 0.0075\n",
      "Epoch 16/80\n",
      "10261/10261 [==============================] - 7s - loss: 9.3986e-04 - val_loss: 0.0043\n",
      "Epoch 17/80\n",
      "10261/10261 [==============================] - 7s - loss: 9.0279e-04 - val_loss: 0.0040\n",
      "Epoch 18/80\n",
      "10261/10261 [==============================] - 7s - loss: 8.5730e-04 - val_loss: 0.0064\n",
      "Epoch 19/80\n",
      "10261/10261 [==============================] - 7s - loss: 8.0588e-04 - val_loss: 0.0066\n",
      "Epoch 20/80\n",
      "10261/10261 [==============================] - 7s - loss: 7.9069e-04 - val_loss: 0.0028\n",
      "Epoch 21/80\n",
      "10261/10261 [==============================] - 7s - loss: 7.5328e-04 - val_loss: 0.0041\n",
      "Epoch 22/80\n",
      "10261/10261 [==============================] - 7s - loss: 7.3268e-04 - val_loss: 0.0046\n",
      "Epoch 23/80\n",
      "10261/10261 [==============================] - 7s - loss: 7.1783e-04 - val_loss: 0.0068\n",
      "Epoch 24/80\n",
      "10261/10261 [==============================] - 7s - loss: 6.7615e-04 - val_loss: 0.0074\n",
      "Epoch 25/80\n",
      "10261/10261 [==============================] - 7s - loss: 6.6970e-04 - val_loss: 0.0045\n",
      "Epoch 26/80\n",
      "10261/10261 [==============================] - 7s - loss: 6.6105e-04 - val_loss: 0.0064\n",
      "Epoch 27/80\n",
      "10261/10261 [==============================] - 7s - loss: 6.2022e-04 - val_loss: 0.0049\n",
      "Epoch 28/80\n",
      "10261/10261 [==============================] - 7s - loss: 6.0461e-04 - val_loss: 0.0052\n",
      "Epoch 29/80\n",
      "10261/10261 [==============================] - 7s - loss: 6.0787e-04 - val_loss: 0.0074\n",
      "Epoch 30/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.8132e-04 - val_loss: 0.0040\n",
      "Epoch 31/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.6898e-04 - val_loss: 0.0051\n",
      "Epoch 32/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.6183e-04 - val_loss: 0.0033\n",
      "Epoch 33/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.1855e-04 - val_loss: 0.0072\n",
      "Epoch 34/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.2068e-04 - val_loss: 0.0046\n",
      "Epoch 35/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.0632e-04 - val_loss: 0.0059\n",
      "Epoch 36/80\n",
      "10261/10261 [==============================] - 7s - loss: 5.1613e-04 - val_loss: 0.0062\n",
      "Epoch 37/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.9778e-04 - val_loss: 0.0066\n",
      "Epoch 38/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.7680e-04 - val_loss: 0.0049\n",
      "Epoch 39/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.8437e-04 - val_loss: 0.0064\n",
      "Epoch 40/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.6638e-04 - val_loss: 0.0034\n",
      "Epoch 41/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.4561e-04 - val_loss: 0.0050\n",
      "Epoch 42/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.4993e-04 - val_loss: 0.0052\n",
      "Epoch 43/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.3753e-04 - val_loss: 0.0069\n",
      "Epoch 44/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.3877e-04 - val_loss: 0.0054\n",
      "Epoch 45/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.3207e-04 - val_loss: 0.0058\n",
      "Epoch 46/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.2139e-04 - val_loss: 0.0033\n",
      "Epoch 47/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.2100e-04 - val_loss: 0.0073\n",
      "Epoch 48/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.2256e-04 - val_loss: 0.0066\n",
      "Epoch 49/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.0626e-04 - val_loss: 0.0053\n",
      "Epoch 50/80\n",
      "10261/10261 [==============================] - 7s - loss: 4.0928e-04 - val_loss: 0.0048\n",
      "Epoch 51/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.9011e-04 - val_loss: 0.0047\n",
      "Epoch 52/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.8392e-04 - val_loss: 0.0071\n",
      "Epoch 53/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.8357e-04 - val_loss: 0.0066\n",
      "Epoch 54/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.6604e-04 - val_loss: 0.0048\n",
      "Epoch 55/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.7559e-04 - val_loss: 0.0052\n",
      "Epoch 56/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.8059e-04 - val_loss: 0.0060\n",
      "Epoch 57/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.6136e-04 - val_loss: 0.0063\n",
      "Epoch 58/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.5456e-04 - val_loss: 0.0065\n",
      "Epoch 59/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.4811e-04 - val_loss: 0.0071\n",
      "Epoch 60/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.5564e-04 - val_loss: 0.0051\n",
      "Epoch 61/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.4962e-04 - val_loss: 0.0042\n",
      "Epoch 62/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.3877e-04 - val_loss: 0.0069\n",
      "Epoch 63/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.3487e-04 - val_loss: 0.0067\n",
      "Epoch 64/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.4456e-04 - val_loss: 0.0080\n",
      "Epoch 65/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.2209e-04 - val_loss: 0.0061\n",
      "Epoch 66/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.1501e-04 - val_loss: 0.0072\n",
      "Epoch 67/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.2173e-04 - val_loss: 0.0042\n",
      "Epoch 68/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.1739e-04 - val_loss: 0.0069\n",
      "Epoch 69/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.1034e-04 - val_loss: 0.0081\n",
      "Epoch 70/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.2428e-04 - val_loss: 0.0055\n",
      "Epoch 71/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.0913e-04 - val_loss: 0.0057\n",
      "Epoch 72/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.1515e-04 - val_loss: 0.0046\n",
      "Epoch 73/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.0916e-04 - val_loss: 0.0037\n",
      "Epoch 74/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.0147e-04 - val_loss: 0.0065\n",
      "Epoch 75/80\n",
      "10261/10261 [==============================] - 7s - loss: 2.9653e-04 - val_loss: 0.0058\n",
      "Epoch 76/80\n",
      "10261/10261 [==============================] - 7s - loss: 2.8828e-04 - val_loss: 0.0051\n",
      "Epoch 77/80\n",
      "10261/10261 [==============================] - 7s - loss: 3.1037e-04 - val_loss: 0.0085\n",
      "Epoch 78/80\n",
      "10261/10261 [==============================] - 7s - loss: 2.9363e-04 - val_loss: 0.0072\n",
      "Epoch 79/80\n",
      "10261/10261 [==============================] - 7s - loss: 2.9077e-04 - val_loss: 0.0069\n",
      "Epoch 80/80\n",
      "10261/10261 [==============================] - 7s - loss: 2.7935e-04 - val_loss: 0.0050\n",
      "0.172578766159\n",
      "4.15010997477\n",
      "26.9280602525\n",
      "3.36187296029\n",
      "sequence_testing:3\n",
      "(406, 5, 4096) (406, 3, 32, 32, 3) (406, 3)\n",
      "(10940, 5, 4096) (10940, 3, 32, 32, 3) (10940, 3)\n",
      "Train on 10830 samples, validate on 110 samples\n",
      "Epoch 1/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 2/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 3/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 4/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 5/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 6/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 7/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 8/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 9/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 10/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 11/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 12/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 13/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 14/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 15/80\n",
      "10830/10830 [==============================] - 8s - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 16/80\n",
      "10830/10830 [==============================] - 8s - loss: 9.9745e-04 - val_loss: 0.0050\n",
      "Epoch 17/80\n",
      "10830/10830 [==============================] - 8s - loss: 9.3922e-04 - val_loss: 0.0057\n",
      "Epoch 18/80\n",
      "10830/10830 [==============================] - 8s - loss: 9.0542e-04 - val_loss: 0.0061\n",
      "Epoch 19/80\n",
      "10830/10830 [==============================] - 8s - loss: 8.3810e-04 - val_loss: 0.0029\n",
      "Epoch 20/80\n",
      "10830/10830 [==============================] - 8s - loss: 8.4883e-04 - val_loss: 0.0022\n",
      "Epoch 21/80\n",
      "10830/10830 [==============================] - 8s - loss: 8.0117e-04 - val_loss: 0.0044\n",
      "Epoch 22/80\n",
      "10830/10830 [==============================] - 8s - loss: 7.7019e-04 - val_loss: 0.0051\n",
      "Epoch 23/80\n",
      "10830/10830 [==============================] - 8s - loss: 7.5261e-04 - val_loss: 0.0045\n",
      "Epoch 24/80\n",
      "10830/10830 [==============================] - 8s - loss: 7.0525e-04 - val_loss: 0.0014\n",
      "Epoch 25/80\n",
      "10830/10830 [==============================] - 8s - loss: 7.2213e-04 - val_loss: 0.0045\n",
      "Epoch 26/80\n",
      "10830/10830 [==============================] - 8s - loss: 6.8090e-04 - val_loss: 0.0061\n",
      "Epoch 27/80\n",
      "10830/10830 [==============================] - 8s - loss: 6.5547e-04 - val_loss: 0.0039\n",
      "Epoch 28/80\n",
      "10830/10830 [==============================] - 8s - loss: 6.3002e-04 - val_loss: 0.0054\n",
      "Epoch 29/80\n",
      "10830/10830 [==============================] - 8s - loss: 6.4530e-04 - val_loss: 0.0032\n",
      "Epoch 30/80\n",
      "10830/10830 [==============================] - 8s - loss: 6.0644e-04 - val_loss: 0.0050\n",
      "Epoch 31/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.7221e-04 - val_loss: 0.0060\n",
      "Epoch 32/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.7941e-04 - val_loss: 0.0054\n",
      "Epoch 33/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.6821e-04 - val_loss: 0.0044\n",
      "Epoch 34/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.3122e-04 - val_loss: 0.0023\n",
      "Epoch 35/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.3865e-04 - val_loss: 0.0047\n",
      "Epoch 36/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.4603e-04 - val_loss: 0.0045\n",
      "Epoch 37/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.1142e-04 - val_loss: 0.0047\n",
      "Epoch 38/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.9599e-04 - val_loss: 0.0041\n",
      "Epoch 39/80\n",
      "10830/10830 [==============================] - 8s - loss: 5.0763e-04 - val_loss: 0.0036\n",
      "Epoch 40/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.8697e-04 - val_loss: 0.0034\n",
      "Epoch 41/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.7227e-04 - val_loss: 0.0047\n",
      "Epoch 42/80\n",
      "10830/10830 [==============================] - 7s - loss: 4.7234e-04 - val_loss: 0.0044\n",
      "Epoch 43/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.6885e-04 - val_loss: 0.0035\n",
      "Epoch 44/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.4936e-04 - val_loss: 0.0046\n",
      "Epoch 45/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.4540e-04 - val_loss: 0.0028\n",
      "Epoch 46/80\n",
      "10830/10830 [==============================] - 7s - loss: 4.4001e-04 - val_loss: 0.0042\n",
      "Epoch 47/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.3490e-04 - val_loss: 0.0042\n",
      "Epoch 48/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.1731e-04 - val_loss: 0.0042\n",
      "Epoch 49/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.3252e-04 - val_loss: 0.0040\n",
      "Epoch 50/80\n",
      "10830/10830 [==============================] - 8s - loss: 4.0922e-04 - val_loss: 0.0033\n",
      "Epoch 51/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.9038e-04 - val_loss: 0.0046\n",
      "Epoch 52/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.7943e-04 - val_loss: 0.0041\n",
      "Epoch 53/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.9308e-04 - val_loss: 0.0035\n",
      "Epoch 54/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.7462e-04 - val_loss: 0.0036\n",
      "Epoch 55/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.9463e-04 - val_loss: 0.0063\n",
      "Epoch 56/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.8238e-04 - val_loss: 0.0052\n",
      "Epoch 57/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.7584e-04 - val_loss: 0.0042\n",
      "Epoch 58/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.6439e-04 - val_loss: 0.0047\n",
      "Epoch 59/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.6965e-04 - val_loss: 0.0044\n",
      "Epoch 60/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.5076e-04 - val_loss: 0.0041\n",
      "Epoch 61/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.5230e-04 - val_loss: 0.0050\n",
      "Epoch 62/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.4712e-04 - val_loss: 0.0044\n",
      "Epoch 63/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.4315e-04 - val_loss: 0.0039\n",
      "Epoch 64/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.3649e-04 - val_loss: 0.0041\n",
      "Epoch 65/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.4177e-04 - val_loss: 0.0032\n",
      "Epoch 66/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.3644e-04 - val_loss: 0.0057\n",
      "Epoch 67/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.3411e-04 - val_loss: 0.0046\n",
      "Epoch 68/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.3073e-04 - val_loss: 0.0051\n",
      "Epoch 69/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.2750e-04 - val_loss: 0.0040\n",
      "Epoch 70/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.1392e-04 - val_loss: 0.0041\n",
      "Epoch 71/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.1370e-04 - val_loss: 0.0051\n",
      "Epoch 72/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.0655e-04 - val_loss: 0.0053\n",
      "Epoch 73/80\n",
      "10830/10830 [==============================] - 7s - loss: 3.1110e-04 - val_loss: 0.0047\n",
      "Epoch 74/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.1802e-04 - val_loss: 0.0046\n",
      "Epoch 75/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.0541e-04 - val_loss: 0.0033\n",
      "Epoch 76/80\n",
      "10830/10830 [==============================] - 8s - loss: 3.1573e-04 - val_loss: 0.0042\n",
      "Epoch 77/80\n",
      "10830/10830 [==============================] - 8s - loss: 2.9158e-04 - val_loss: 0.0054\n",
      "Epoch 78/80\n",
      "10830/10830 [==============================] - 8s - loss: 2.9850e-04 - val_loss: 0.0074\n",
      "Epoch 79/80\n",
      "10830/10830 [==============================] - 8s - loss: 2.9789e-04 - val_loss: 0.0060\n",
      "Epoch 80/80\n",
      "10830/10830 [==============================] - 8s - loss: 2.9157e-04 - val_loss: 0.0048\n",
      "0.0801234847085\n",
      "2.99193594376\n",
      "14.1308964714\n",
      "2.07252449727\n",
      "sequence_testing:4\n",
      "(499, 5, 4096) (499, 3, 32, 32, 3) (499, 3)\n",
      "(10847, 5, 4096) (10847, 3, 32, 32, 3) (10847, 3)\n",
      "Train on 10738 samples, validate on 109 samples\n",
      "Epoch 1/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0267 - val_loss: 0.0060\n",
      "Epoch 2/80\n",
      "10738/10738 [==============================] - 7s - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 3/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 4/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0028 - val_loss: 0.0085\n",
      "Epoch 5/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 6/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 7/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 8/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 9/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 10/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 11/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 12/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 13/80\n",
      "10738/10738 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 14/80\n",
      "10738/10738 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 15/80\n",
      "10738/10738 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0035\n",
      "Epoch 16/80\n",
      "10738/10738 [==============================] - 8s - loss: 9.6964e-04 - val_loss: 0.0047\n",
      "Epoch 17/80\n",
      "10738/10738 [==============================] - 8s - loss: 9.4963e-04 - val_loss: 0.0045\n",
      "Epoch 18/80\n",
      "10738/10738 [==============================] - 7s - loss: 8.7838e-04 - val_loss: 0.0050\n",
      "Epoch 19/80\n",
      "10738/10738 [==============================] - 7s - loss: 8.5762e-04 - val_loss: 0.0036\n",
      "Epoch 20/80\n",
      "10738/10738 [==============================] - 7s - loss: 8.4177e-04 - val_loss: 0.0054\n",
      "Epoch 21/80\n",
      "10738/10738 [==============================] - 7s - loss: 7.8705e-04 - val_loss: 0.0030\n",
      "Epoch 22/80\n",
      "10738/10738 [==============================] - 7s - loss: 7.5516e-04 - val_loss: 0.0039\n",
      "Epoch 23/80\n",
      "10738/10738 [==============================] - 8s - loss: 7.3843e-04 - val_loss: 0.0056\n",
      "Epoch 24/80\n",
      "10738/10738 [==============================] - 7s - loss: 6.9988e-04 - val_loss: 0.0058\n",
      "Epoch 25/80\n",
      "10738/10738 [==============================] - 8s - loss: 7.0492e-04 - val_loss: 0.0050\n",
      "Epoch 26/80\n",
      "10738/10738 [==============================] - 7s - loss: 6.8362e-04 - val_loss: 0.0061\n",
      "Epoch 27/80\n",
      "10738/10738 [==============================] - 8s - loss: 6.6733e-04 - val_loss: 0.0054\n",
      "Epoch 28/80\n",
      "10738/10738 [==============================] - 7s - loss: 6.3620e-04 - val_loss: 0.0061\n",
      "Epoch 29/80\n",
      "10738/10738 [==============================] - 7s - loss: 6.1956e-04 - val_loss: 0.0064\n",
      "Epoch 30/80\n",
      "10738/10738 [==============================] - 8s - loss: 6.2209e-04 - val_loss: 0.0039\n",
      "Epoch 31/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.7596e-04 - val_loss: 0.0038\n",
      "Epoch 32/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.7826e-04 - val_loss: 0.0051\n",
      "Epoch 33/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.6281e-04 - val_loss: 0.0057\n",
      "Epoch 34/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.4922e-04 - val_loss: 0.0061\n",
      "Epoch 35/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.1419e-04 - val_loss: 0.0068\n",
      "Epoch 36/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.2099e-04 - val_loss: 0.0042\n",
      "Epoch 37/80\n",
      "10738/10738 [==============================] - 7s - loss: 5.1769e-04 - val_loss: 0.0040\n",
      "Epoch 38/80\n",
      "10738/10738 [==============================] - 8s - loss: 4.8368e-04 - val_loss: 0.0056\n",
      "Epoch 39/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.8969e-04 - val_loss: 0.0044\n",
      "Epoch 40/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.7412e-04 - val_loss: 0.0077\n",
      "Epoch 41/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.8034e-04 - val_loss: 0.0058\n",
      "Epoch 42/80\n",
      "10738/10738 [==============================] - 8s - loss: 4.5974e-04 - val_loss: 0.0051\n",
      "Epoch 43/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.5828e-04 - val_loss: 0.0061\n",
      "Epoch 44/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.4819e-04 - val_loss: 0.0045\n",
      "Epoch 45/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.5266e-04 - val_loss: 0.0051\n",
      "Epoch 46/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.3271e-04 - val_loss: 0.0051\n",
      "Epoch 47/80\n",
      "10738/10738 [==============================] - 8s - loss: 4.1325e-04 - val_loss: 0.0050\n",
      "Epoch 48/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.1724e-04 - val_loss: 0.0033\n",
      "Epoch 49/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.1481e-04 - val_loss: 0.0042\n",
      "Epoch 50/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.1109e-04 - val_loss: 0.0042\n",
      "Epoch 51/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.9665e-04 - val_loss: 0.0058\n",
      "Epoch 52/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.9678e-04 - val_loss: 0.0066\n",
      "Epoch 53/80\n",
      "10738/10738 [==============================] - 7s - loss: 4.0315e-04 - val_loss: 0.0066\n",
      "Epoch 54/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.9302e-04 - val_loss: 0.0052\n",
      "Epoch 55/80\n",
      "10738/10738 [==============================] - 8s - loss: 3.8703e-04 - val_loss: 0.0057\n",
      "Epoch 56/80\n",
      "10738/10738 [==============================] - 8s - loss: 3.6754e-04 - val_loss: 0.0050\n",
      "Epoch 57/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.6836e-04 - val_loss: 0.0073\n",
      "Epoch 58/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.7545e-04 - val_loss: 0.0055\n",
      "Epoch 59/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.6127e-04 - val_loss: 0.0051\n",
      "Epoch 60/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.6608e-04 - val_loss: 0.0054\n",
      "Epoch 61/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.5332e-04 - val_loss: 0.0048\n",
      "Epoch 62/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.5089e-04 - val_loss: 0.0051\n",
      "Epoch 63/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.4474e-04 - val_loss: 0.0061\n",
      "Epoch 64/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.3909e-04 - val_loss: 0.0072\n",
      "Epoch 65/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.5646e-04 - val_loss: 0.0058\n",
      "Epoch 66/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.3352e-04 - val_loss: 0.0067\n",
      "Epoch 67/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.3898e-04 - val_loss: 0.0072\n",
      "Epoch 68/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.3604e-04 - val_loss: 0.0061\n",
      "Epoch 69/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.1714e-04 - val_loss: 0.0054\n",
      "Epoch 70/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.1543e-04 - val_loss: 0.0041\n",
      "Epoch 71/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.2120e-04 - val_loss: 0.0075\n",
      "Epoch 72/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.0524e-04 - val_loss: 0.0056\n",
      "Epoch 73/80\n",
      "10738/10738 [==============================] - 8s - loss: 3.2860e-04 - val_loss: 0.0058\n",
      "Epoch 74/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.0051e-04 - val_loss: 0.0064\n",
      "Epoch 75/80\n",
      "10738/10738 [==============================] - 7s - loss: 3.0708e-04 - val_loss: 0.0048\n",
      "Epoch 76/80\n",
      "10738/10738 [==============================] - 8s - loss: 2.9702e-04 - val_loss: 0.0063\n",
      "Epoch 77/80\n",
      "10738/10738 [==============================] - 8s - loss: 3.0647e-04 - val_loss: 0.0047\n",
      "Epoch 78/80\n",
      "10738/10738 [==============================] - 8s - loss: 2.9423e-04 - val_loss: 0.0053\n",
      "Epoch 79/80\n",
      "10738/10738 [==============================] - 8s - loss: 2.9576e-04 - val_loss: 0.0061\n",
      "Epoch 80/80\n",
      "10738/10738 [==============================] - 8s - loss: 2.8855e-04 - val_loss: 0.0061\n",
      "0.0449231882161\n",
      "3.39749701232\n",
      "17.5519286869\n",
      "1.9913018791\n",
      "sequence_testing:5\n",
      "(276, 5, 4096) (276, 3, 32, 32, 3) (276, 3)\n",
      "(11070, 5, 4096) (11070, 3, 32, 32, 3) (11070, 3)\n",
      "Train on 10959 samples, validate on 111 samples\n",
      "Epoch 1/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0270 - val_loss: 0.0054\n",
      "Epoch 2/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 3/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 4/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0029 - val_loss: 0.0072\n",
      "Epoch 5/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0025 - val_loss: 0.0118\n",
      "Epoch 6/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 7/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 8/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 9/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 10/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 11/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 12/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 13/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 14/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 15/80\n",
      "10959/10959 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0084\n",
      "Epoch 16/80\n",
      "10959/10959 [==============================] - 8s - loss: 9.9082e-04 - val_loss: 0.0049\n",
      "Epoch 17/80\n",
      "10959/10959 [==============================] - 8s - loss: 9.7260e-04 - val_loss: 0.0052\n",
      "Epoch 18/80\n",
      "10959/10959 [==============================] - 8s - loss: 9.2126e-04 - val_loss: 0.0054\n",
      "Epoch 19/80\n",
      "10959/10959 [==============================] - 8s - loss: 8.7925e-04 - val_loss: 0.0050\n",
      "Epoch 20/80\n",
      "10959/10959 [==============================] - 8s - loss: 8.3900e-04 - val_loss: 0.0035\n",
      "Epoch 21/80\n",
      "10959/10959 [==============================] - 8s - loss: 8.2922e-04 - val_loss: 0.0059\n",
      "Epoch 22/80\n",
      "10959/10959 [==============================] - 8s - loss: 7.9932e-04 - val_loss: 0.0046\n",
      "Epoch 23/80\n",
      "10959/10959 [==============================] - 8s - loss: 7.4742e-04 - val_loss: 0.0073\n",
      "Epoch 24/80\n",
      "10959/10959 [==============================] - 8s - loss: 7.4272e-04 - val_loss: 0.0057\n",
      "Epoch 25/80\n",
      "10959/10959 [==============================] - 8s - loss: 7.1207e-04 - val_loss: 0.0035\n",
      "Epoch 26/80\n",
      "10959/10959 [==============================] - 8s - loss: 6.8769e-04 - val_loss: 0.0054\n",
      "Epoch 27/80\n",
      "10959/10959 [==============================] - 8s - loss: 6.7956e-04 - val_loss: 0.0042\n",
      "Epoch 28/80\n",
      "10959/10959 [==============================] - 8s - loss: 6.5063e-04 - val_loss: 0.0041\n",
      "Epoch 29/80\n",
      "10959/10959 [==============================] - 8s - loss: 6.3456e-04 - val_loss: 0.0053\n",
      "Epoch 30/80\n",
      "10959/10959 [==============================] - 8s - loss: 6.1823e-04 - val_loss: 0.0054\n",
      "Epoch 31/80\n",
      "10959/10959 [==============================] - 8s - loss: 6.0066e-04 - val_loss: 0.0051\n",
      "Epoch 32/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.9058e-04 - val_loss: 0.0035\n",
      "Epoch 33/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.7949e-04 - val_loss: 0.0040\n",
      "Epoch 34/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.6470e-04 - val_loss: 0.0057\n",
      "Epoch 35/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.5297e-04 - val_loss: 0.0044\n",
      "Epoch 36/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.2805e-04 - val_loss: 0.0054\n",
      "Epoch 37/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.3639e-04 - val_loss: 0.0059\n",
      "Epoch 38/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.9837e-04 - val_loss: 0.0072\n",
      "Epoch 39/80\n",
      "10959/10959 [==============================] - 8s - loss: 5.1171e-04 - val_loss: 0.0046\n",
      "Epoch 40/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.8721e-04 - val_loss: 0.0033\n",
      "Epoch 41/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.9230e-04 - val_loss: 0.0047\n",
      "Epoch 42/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.7262e-04 - val_loss: 0.0057\n",
      "Epoch 43/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.7166e-04 - val_loss: 0.0070\n",
      "Epoch 44/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.6767e-04 - val_loss: 0.0043\n",
      "Epoch 45/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.5675e-04 - val_loss: 0.0038\n",
      "Epoch 46/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.4731e-04 - val_loss: 0.0056\n",
      "Epoch 47/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.3933e-04 - val_loss: 0.0052\n",
      "Epoch 48/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.3635e-04 - val_loss: 0.0052\n",
      "Epoch 49/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.2814e-04 - val_loss: 0.0063\n",
      "Epoch 50/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.1947e-04 - val_loss: 0.0059\n",
      "Epoch 51/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.1627e-04 - val_loss: 0.0053\n",
      "Epoch 52/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.0804e-04 - val_loss: 0.0064\n",
      "Epoch 53/80\n",
      "10959/10959 [==============================] - 8s - loss: 4.0505e-04 - val_loss: 0.0051\n",
      "Epoch 54/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.8821e-04 - val_loss: 0.0070\n",
      "Epoch 55/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.9229e-04 - val_loss: 0.0071\n",
      "Epoch 56/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.9817e-04 - val_loss: 0.0069\n",
      "Epoch 57/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.7302e-04 - val_loss: 0.0076\n",
      "Epoch 58/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.7607e-04 - val_loss: 0.0055\n",
      "Epoch 59/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.5207e-04 - val_loss: 0.0063\n",
      "Epoch 60/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.6204e-04 - val_loss: 0.0060\n",
      "Epoch 61/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.5652e-04 - val_loss: 0.0044\n",
      "Epoch 62/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.5750e-04 - val_loss: 0.0053\n",
      "Epoch 63/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.5261e-04 - val_loss: 0.0055\n",
      "Epoch 64/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.4782e-04 - val_loss: 0.0050\n",
      "Epoch 65/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.3997e-04 - val_loss: 0.0046\n",
      "Epoch 66/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.3389e-04 - val_loss: 0.0066\n",
      "Epoch 67/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.4012e-04 - val_loss: 0.0058\n",
      "Epoch 68/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.3421e-04 - val_loss: 0.0065\n",
      "Epoch 69/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.1963e-04 - val_loss: 0.0045\n",
      "Epoch 70/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.2255e-04 - val_loss: 0.0053\n",
      "Epoch 71/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.1392e-04 - val_loss: 0.0050\n",
      "Epoch 72/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.0800e-04 - val_loss: 0.0050\n",
      "Epoch 73/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.1604e-04 - val_loss: 0.0074\n",
      "Epoch 74/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.0618e-04 - val_loss: 0.0064\n",
      "Epoch 75/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.0972e-04 - val_loss: 0.0069\n",
      "Epoch 76/80\n",
      "10959/10959 [==============================] - 8s - loss: 3.0189e-04 - val_loss: 0.0055\n",
      "Epoch 77/80\n",
      "10959/10959 [==============================] - 8s - loss: 2.9515e-04 - val_loss: 0.0058\n",
      "Epoch 78/80\n",
      "10959/10959 [==============================] - 8s - loss: 2.8512e-04 - val_loss: 0.0077\n",
      "Epoch 79/80\n",
      "10959/10959 [==============================] - 8s - loss: 2.9192e-04 - val_loss: 0.0059\n",
      "Epoch 80/80\n",
      "10959/10959 [==============================] - 8s - loss: 2.8399e-04 - val_loss: 0.0053\n",
      "0.0426052318642\n",
      "2.27155912926\n",
      "10.2496040219\n",
      "1.71744941033\n",
      "sequence_testing:6\n",
      "(956, 5, 4096) (956, 3, 32, 32, 3) (956, 3)\n",
      "(10390, 5, 4096) (10390, 3, 32, 32, 3) (10390, 3)\n",
      "Train on 10286 samples, validate on 104 samples\n",
      "Epoch 1/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0279 - val_loss: 0.0145\n",
      "Epoch 2/80\n",
      "10286/10286 [==============================] - 8s - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 3/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0036 - val_loss: 0.0120\n",
      "Epoch 4/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 5/80\n",
      "10286/10286 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 6/80\n",
      "10286/10286 [==============================] - 8s - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 7/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 8/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 9/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 10/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0088\n",
      "Epoch 11/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 12/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 13/80\n",
      "10286/10286 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 14/80\n",
      "10286/10286 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 15/80\n",
      "10286/10286 [==============================] - 8s - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 16/80\n",
      "10286/10286 [==============================] - 8s - loss: 9.6000e-04 - val_loss: 0.0023\n",
      "Epoch 17/80\n",
      "10286/10286 [==============================] - 8s - loss: 9.2518e-04 - val_loss: 0.0071\n",
      "Epoch 18/80\n",
      "10286/10286 [==============================] - 8s - loss: 8.6105e-04 - val_loss: 0.0057\n",
      "Epoch 19/80\n",
      "10286/10286 [==============================] - 7s - loss: 8.1891e-04 - val_loss: 0.0062\n",
      "Epoch 20/80\n",
      "10286/10286 [==============================] - 7s - loss: 8.2844e-04 - val_loss: 0.0029\n",
      "Epoch 21/80\n",
      "10286/10286 [==============================] - 7s - loss: 7.6865e-04 - val_loss: 0.0068\n",
      "Epoch 22/80\n",
      "10286/10286 [==============================] - 7s - loss: 7.2939e-04 - val_loss: 0.0050\n",
      "Epoch 23/80\n",
      "10286/10286 [==============================] - 7s - loss: 7.2135e-04 - val_loss: 0.0057\n",
      "Epoch 24/80\n",
      "10286/10286 [==============================] - 7s - loss: 7.0754e-04 - val_loss: 0.0055\n",
      "Epoch 25/80\n",
      "10286/10286 [==============================] - 7s - loss: 6.8469e-04 - val_loss: 0.0042\n",
      "Epoch 26/80\n",
      "10286/10286 [==============================] - 7s - loss: 6.6152e-04 - val_loss: 0.0043\n",
      "Epoch 27/80\n",
      "10286/10286 [==============================] - 7s - loss: 6.1564e-04 - val_loss: 0.0045\n",
      "Epoch 28/80\n",
      "10286/10286 [==============================] - 7s - loss: 6.2361e-04 - val_loss: 0.0055\n",
      "Epoch 29/80\n",
      "10286/10286 [==============================] - 7s - loss: 6.0533e-04 - val_loss: 0.0049\n",
      "Epoch 30/80\n",
      "10286/10286 [==============================] - 7s - loss: 6.1400e-04 - val_loss: 0.0056\n",
      "Epoch 31/80\n",
      "10286/10286 [==============================] - 7s - loss: 5.7082e-04 - val_loss: 0.0076\n",
      "Epoch 32/80\n",
      "10286/10286 [==============================] - 7s - loss: 5.7936e-04 - val_loss: 0.0056\n",
      "Epoch 33/80\n",
      "10286/10286 [==============================] - 7s - loss: 5.6741e-04 - val_loss: 0.0053\n",
      "Epoch 34/80\n",
      "10286/10286 [==============================] - 7s - loss: 5.4045e-04 - val_loss: 0.0042\n",
      "Epoch 35/80\n",
      "10286/10286 [==============================] - 7s - loss: 5.3575e-04 - val_loss: 0.0040\n",
      "Epoch 36/80\n",
      "10286/10286 [==============================] - 7s - loss: 5.1765e-04 - val_loss: 0.0050\n",
      "Epoch 37/80\n",
      "10286/10286 [==============================] - 8s - loss: 5.1393e-04 - val_loss: 0.0062\n",
      "Epoch 38/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.9880e-04 - val_loss: 0.0047\n",
      "Epoch 39/80\n",
      "10286/10286 [==============================] - 8s - loss: 5.0667e-04 - val_loss: 0.0075\n",
      "Epoch 40/80\n",
      "10286/10286 [==============================] - 8s - loss: 4.8860e-04 - val_loss: 0.0065\n",
      "Epoch 41/80\n",
      "10286/10286 [==============================] - 8s - loss: 4.6008e-04 - val_loss: 0.0061\n",
      "Epoch 42/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.6398e-04 - val_loss: 0.0050\n",
      "Epoch 43/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.4894e-04 - val_loss: 0.0080\n",
      "Epoch 44/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.4229e-04 - val_loss: 0.0055\n",
      "Epoch 45/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.2092e-04 - val_loss: 0.0055\n",
      "Epoch 46/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.2434e-04 - val_loss: 0.0058\n",
      "Epoch 47/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.1021e-04 - val_loss: 0.0059\n",
      "Epoch 48/80\n",
      "10286/10286 [==============================] - 7s - loss: 4.1477e-04 - val_loss: 0.0042\n",
      "Epoch 49/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.9111e-04 - val_loss: 0.0050\n",
      "Epoch 50/80\n",
      "10286/10286 [==============================] - 8s - loss: 4.1254e-04 - val_loss: 0.0053\n",
      "Epoch 51/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.9787e-04 - val_loss: 0.0053\n",
      "Epoch 52/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.8279e-04 - val_loss: 0.0057\n",
      "Epoch 53/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.8142e-04 - val_loss: 0.0066\n",
      "Epoch 54/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.7257e-04 - val_loss: 0.0051\n",
      "Epoch 55/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.7081e-04 - val_loss: 0.0063\n",
      "Epoch 56/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.6322e-04 - val_loss: 0.0055\n",
      "Epoch 57/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.6740e-04 - val_loss: 0.0056\n",
      "Epoch 58/80\n",
      "10286/10286 [==============================] - 7s - loss: 3.5266e-04 - val_loss: 0.0050\n",
      "Epoch 59/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.5852e-04 - val_loss: 0.0071\n",
      "Epoch 60/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.4979e-04 - val_loss: 0.0076\n",
      "Epoch 61/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.3936e-04 - val_loss: 0.0040\n",
      "Epoch 62/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.5068e-04 - val_loss: 0.0064\n",
      "Epoch 63/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.4164e-04 - val_loss: 0.0048\n",
      "Epoch 64/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.3499e-04 - val_loss: 0.0051\n",
      "Epoch 65/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.2756e-04 - val_loss: 0.0080\n",
      "Epoch 66/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.2943e-04 - val_loss: 0.0063\n",
      "Epoch 67/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.3069e-04 - val_loss: 0.0051\n",
      "Epoch 68/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.2194e-04 - val_loss: 0.0053\n",
      "Epoch 69/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.1013e-04 - val_loss: 0.0049\n",
      "Epoch 70/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.0321e-04 - val_loss: 0.0048\n",
      "Epoch 71/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.9992e-04 - val_loss: 0.0035\n",
      "Epoch 72/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.0674e-04 - val_loss: 0.0048\n",
      "Epoch 73/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.0695e-04 - val_loss: 0.0065\n",
      "Epoch 74/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.8529e-04 - val_loss: 0.0061\n",
      "Epoch 75/80\n",
      "10286/10286 [==============================] - 8s - loss: 3.1313e-04 - val_loss: 0.0047\n",
      "Epoch 76/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.9869e-04 - val_loss: 0.0067\n",
      "Epoch 77/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.9232e-04 - val_loss: 0.0060\n",
      "Epoch 78/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.8591e-04 - val_loss: 0.0066\n",
      "Epoch 79/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.9221e-04 - val_loss: 0.0054\n",
      "Epoch 80/80\n",
      "10286/10286 [==============================] - 8s - loss: 2.7614e-04 - val_loss: 0.0050\n",
      "0.0422673280993\n",
      "4.83287732079\n",
      "18.5584710102\n",
      "3.46550222109\n",
      "sequence_testing:7\n",
      "(708, 5, 4096) (708, 3, 32, 32, 3) (708, 3)\n",
      "(10638, 5, 4096) (10638, 3, 32, 32, 3) (10638, 3)\n",
      "Train on 10531 samples, validate on 107 samples\n",
      "Epoch 1/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0280 - val_loss: 0.0141\n",
      "Epoch 2/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 3/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 4/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 5/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 6/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 7/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 8/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 9/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 10/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 11/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 12/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 13/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 14/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 15/80\n",
      "10531/10531 [==============================] - 8s - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 16/80\n",
      "10531/10531 [==============================] - 8s - loss: 9.9061e-04 - val_loss: 0.0063\n",
      "Epoch 17/80\n",
      "10531/10531 [==============================] - 8s - loss: 9.6279e-04 - val_loss: 0.0031\n",
      "Epoch 18/80\n",
      "10531/10531 [==============================] - 8s - loss: 9.1851e-04 - val_loss: 0.0046\n",
      "Epoch 19/80\n",
      "10531/10531 [==============================] - 8s - loss: 8.7140e-04 - val_loss: 0.0036\n",
      "Epoch 20/80\n",
      "10531/10531 [==============================] - 8s - loss: 8.3444e-04 - val_loss: 0.0072\n",
      "Epoch 21/80\n",
      "10531/10531 [==============================] - 8s - loss: 8.0911e-04 - val_loss: 0.0049\n",
      "Epoch 22/80\n",
      "10531/10531 [==============================] - 8s - loss: 7.7203e-04 - val_loss: 0.0056\n",
      "Epoch 23/80\n",
      "10531/10531 [==============================] - 8s - loss: 7.3565e-04 - val_loss: 0.0054\n",
      "Epoch 24/80\n",
      "10531/10531 [==============================] - 8s - loss: 7.2509e-04 - val_loss: 0.0041\n",
      "Epoch 25/80\n",
      "10531/10531 [==============================] - 8s - loss: 6.9606e-04 - val_loss: 0.0059\n",
      "Epoch 26/80\n",
      "10531/10531 [==============================] - 8s - loss: 6.6501e-04 - val_loss: 0.0056\n",
      "Epoch 27/80\n",
      "10531/10531 [==============================] - 8s - loss: 6.6421e-04 - val_loss: 0.0054\n",
      "Epoch 28/80\n",
      "10531/10531 [==============================] - 8s - loss: 6.4660e-04 - val_loss: 0.0052\n",
      "Epoch 29/80\n",
      "10531/10531 [==============================] - 8s - loss: 6.4072e-04 - val_loss: 0.0037\n",
      "Epoch 30/80\n",
      "10531/10531 [==============================] - 8s - loss: 6.0399e-04 - val_loss: 0.0060\n",
      "Epoch 31/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.9542e-04 - val_loss: 0.0046\n",
      "Epoch 32/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.6649e-04 - val_loss: 0.0050\n",
      "Epoch 33/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.5486e-04 - val_loss: 0.0049\n",
      "Epoch 34/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.5338e-04 - val_loss: 0.0031\n",
      "Epoch 35/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.3680e-04 - val_loss: 0.0060\n",
      "Epoch 36/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.2101e-04 - val_loss: 0.0049\n",
      "Epoch 37/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.1687e-04 - val_loss: 0.0050\n",
      "Epoch 38/80\n",
      "10531/10531 [==============================] - 8s - loss: 5.1423e-04 - val_loss: 0.0041\n",
      "Epoch 39/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.8752e-04 - val_loss: 0.0064\n",
      "Epoch 40/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.8812e-04 - val_loss: 0.0054\n",
      "Epoch 41/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.7888e-04 - val_loss: 0.0064\n",
      "Epoch 42/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.6244e-04 - val_loss: 0.0039\n",
      "Epoch 43/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.5730e-04 - val_loss: 0.0064\n",
      "Epoch 44/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.5116e-04 - val_loss: 0.0059\n",
      "Epoch 45/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.5604e-04 - val_loss: 0.0066\n",
      "Epoch 46/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.3459e-04 - val_loss: 0.0044\n",
      "Epoch 47/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.3985e-04 - val_loss: 0.0034\n",
      "Epoch 48/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.3385e-04 - val_loss: 0.0049\n",
      "Epoch 49/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.9780e-04 - val_loss: 0.0046\n",
      "Epoch 50/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.0937e-04 - val_loss: 0.0043\n",
      "Epoch 51/80\n",
      "10531/10531 [==============================] - 8s - loss: 4.0399e-04 - val_loss: 0.0023\n",
      "Epoch 52/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.9151e-04 - val_loss: 0.0060\n",
      "Epoch 53/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.9936e-04 - val_loss: 0.0052\n",
      "Epoch 54/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.9876e-04 - val_loss: 0.0042\n",
      "Epoch 55/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.7216e-04 - val_loss: 0.0086\n",
      "Epoch 56/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.6764e-04 - val_loss: 0.0060\n",
      "Epoch 57/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.6690e-04 - val_loss: 0.0064\n",
      "Epoch 58/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.6761e-04 - val_loss: 0.0055\n",
      "Epoch 59/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.5867e-04 - val_loss: 0.0053\n",
      "Epoch 60/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.4511e-04 - val_loss: 0.0072\n",
      "Epoch 61/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.5384e-04 - val_loss: 0.0060\n",
      "Epoch 62/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.3703e-04 - val_loss: 0.0052\n",
      "Epoch 63/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.4587e-04 - val_loss: 0.0049\n",
      "Epoch 64/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.4545e-04 - val_loss: 0.0060\n",
      "Epoch 65/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.2025e-04 - val_loss: 0.0061\n",
      "Epoch 66/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.3829e-04 - val_loss: 0.0055\n",
      "Epoch 67/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.4097e-04 - val_loss: 0.0071\n",
      "Epoch 68/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.2679e-04 - val_loss: 0.0057\n",
      "Epoch 69/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.1269e-04 - val_loss: 0.0059\n",
      "Epoch 70/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.2484e-04 - val_loss: 0.0068\n",
      "Epoch 71/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.0779e-04 - val_loss: 0.0026\n",
      "Epoch 72/80\n",
      "10531/10531 [==============================] - 8s - loss: 2.9668e-04 - val_loss: 0.0063\n",
      "Epoch 73/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.1877e-04 - val_loss: 0.0065\n",
      "Epoch 74/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.0368e-04 - val_loss: 0.0051\n",
      "Epoch 75/80\n",
      "10531/10531 [==============================] - 8s - loss: 3.1318e-04 - val_loss: 0.0051\n",
      "Epoch 76/80\n",
      "10531/10531 [==============================] - 8s - loss: 2.9864e-04 - val_loss: 0.0056\n",
      "Epoch 77/80\n",
      "10531/10531 [==============================] - 8s - loss: 2.9670e-04 - val_loss: 0.0070\n",
      "Epoch 78/80\n",
      "10531/10531 [==============================] - 8s - loss: 2.9534e-04 - val_loss: 0.0067\n",
      "Epoch 79/80\n",
      "10531/10531 [==============================] - 8s - loss: 2.9448e-04 - val_loss: 0.0047\n",
      "Epoch 80/80\n",
      "10531/10531 [==============================] - 8s - loss: 2.8540e-04 - val_loss: 0.0059\n",
      "0.0377514689096\n",
      "3.5838790234\n",
      "16.5871401466\n",
      "2.08808982566\n",
      "sequence_testing:8\n",
      "(555, 5, 4096) (555, 3, 32, 32, 3) (555, 3)\n",
      "(10791, 5, 4096) (10791, 3, 32, 32, 3) (10791, 3)\n",
      "Train on 10683 samples, validate on 108 samples\n",
      "Epoch 1/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0272 - val_loss: 0.0020\n",
      "Epoch 2/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 3/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 4/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 5/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 6/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 7/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 8/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 9/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 10/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 11/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 12/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 13/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 14/80\n",
      "10683/10683 [==============================] - 8s - loss: 0.0010 - val_loss: 0.0053\n",
      "Epoch 15/80\n",
      "10683/10683 [==============================] - 8s - loss: 9.7119e-04 - val_loss: 0.0042\n",
      "Epoch 16/80\n",
      "10683/10683 [==============================] - 8s - loss: 9.0405e-04 - val_loss: 0.0044\n",
      "Epoch 17/80\n",
      "10683/10683 [==============================] - 8s - loss: 8.7405e-04 - val_loss: 0.0042\n",
      "Epoch 18/80\n",
      "10683/10683 [==============================] - 8s - loss: 8.4913e-04 - val_loss: 0.0052\n",
      "Epoch 19/80\n",
      "10683/10683 [==============================] - 8s - loss: 8.0120e-04 - val_loss: 0.0040\n",
      "Epoch 20/80\n",
      "10683/10683 [==============================] - 8s - loss: 7.7381e-04 - val_loss: 0.0036\n",
      "Epoch 21/80\n",
      "10683/10683 [==============================] - 8s - loss: 7.1937e-04 - val_loss: 0.0064\n",
      "Epoch 22/80\n",
      "10683/10683 [==============================] - 8s - loss: 7.2171e-04 - val_loss: 0.0039\n",
      "Epoch 23/80\n",
      "10683/10683 [==============================] - 8s - loss: 6.9899e-04 - val_loss: 0.0064\n",
      "Epoch 24/80\n",
      "10683/10683 [==============================] - 8s - loss: 6.7382e-04 - val_loss: 0.0066\n",
      "Epoch 25/80\n",
      "10683/10683 [==============================] - 8s - loss: 6.5358e-04 - val_loss: 0.0048\n",
      "Epoch 26/80\n",
      "10683/10683 [==============================] - 8s - loss: 6.4761e-04 - val_loss: 0.0037\n",
      "Epoch 27/80\n",
      "10683/10683 [==============================] - 8s - loss: 6.2191e-04 - val_loss: 0.0043\n",
      "Epoch 28/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.9750e-04 - val_loss: 0.0054\n",
      "Epoch 29/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.7479e-04 - val_loss: 0.0032\n",
      "Epoch 30/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.8045e-04 - val_loss: 0.0050\n",
      "Epoch 31/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.6298e-04 - val_loss: 0.0043\n",
      "Epoch 32/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.3524e-04 - val_loss: 0.0054\n",
      "Epoch 33/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.2430e-04 - val_loss: 0.0055\n",
      "Epoch 34/80\n",
      "10683/10683 [==============================] - 8s - loss: 5.1705e-04 - val_loss: 0.0052\n",
      "Epoch 35/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.9023e-04 - val_loss: 0.0050\n",
      "Epoch 36/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.7912e-04 - val_loss: 0.0038\n",
      "Epoch 37/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.8646e-04 - val_loss: 0.0045\n",
      "Epoch 38/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.7311e-04 - val_loss: 0.0058\n",
      "Epoch 39/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.5953e-04 - val_loss: 0.0042\n",
      "Epoch 40/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.5385e-04 - val_loss: 0.0036\n",
      "Epoch 41/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.4417e-04 - val_loss: 0.0054\n",
      "Epoch 42/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.3631e-04 - val_loss: 0.0067\n",
      "Epoch 43/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.3158e-04 - val_loss: 0.0053\n",
      "Epoch 44/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.2747e-04 - val_loss: 0.0041\n",
      "Epoch 45/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.9723e-04 - val_loss: 0.0067\n",
      "Epoch 46/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.0433e-04 - val_loss: 0.0067\n",
      "Epoch 47/80\n",
      "10683/10683 [==============================] - 8s - loss: 4.0601e-04 - val_loss: 0.0050\n",
      "Epoch 48/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.9244e-04 - val_loss: 0.0044\n",
      "Epoch 49/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.9037e-04 - val_loss: 0.0052\n",
      "Epoch 50/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.8634e-04 - val_loss: 0.0038\n",
      "Epoch 51/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.7358e-04 - val_loss: 0.0054\n",
      "Epoch 52/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.6250e-04 - val_loss: 0.0047\n",
      "Epoch 53/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.7061e-04 - val_loss: 0.0059\n",
      "Epoch 54/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.6112e-04 - val_loss: 0.0039\n",
      "Epoch 55/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.5178e-04 - val_loss: 0.0063\n",
      "Epoch 56/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.3956e-04 - val_loss: 0.0065\n",
      "Epoch 57/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.4100e-04 - val_loss: 0.0051\n",
      "Epoch 58/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.5381e-04 - val_loss: 0.0042\n",
      "Epoch 59/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.3740e-04 - val_loss: 0.0032\n",
      "Epoch 60/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.3312e-04 - val_loss: 0.0050\n",
      "Epoch 61/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.1872e-04 - val_loss: 0.0026\n",
      "Epoch 62/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.2236e-04 - val_loss: 0.0033\n",
      "Epoch 63/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.3145e-04 - val_loss: 0.0041\n",
      "Epoch 64/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.2137e-04 - val_loss: 0.0046\n",
      "Epoch 65/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.3835e-04 - val_loss: 0.0043\n",
      "Epoch 66/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.1551e-04 - val_loss: 0.0048\n",
      "Epoch 67/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.1566e-04 - val_loss: 0.0068\n",
      "Epoch 68/80\n",
      "10683/10683 [==============================] - 8s - loss: 3.1042e-04 - val_loss: 0.0055\n",
      "Epoch 69/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.9918e-04 - val_loss: 0.0068\n",
      "Epoch 70/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.9831e-04 - val_loss: 0.0049\n",
      "Epoch 71/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.9668e-04 - val_loss: 0.0037\n",
      "Epoch 72/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.8689e-04 - val_loss: 0.0057\n",
      "Epoch 73/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.9297e-04 - val_loss: 0.0065\n",
      "Epoch 74/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.9160e-04 - val_loss: 0.0048\n",
      "Epoch 75/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.8376e-04 - val_loss: 0.0047\n",
      "Epoch 76/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.8973e-04 - val_loss: 0.0059\n",
      "Epoch 77/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.8333e-04 - val_loss: 0.0056\n",
      "Epoch 78/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.8964e-04 - val_loss: 0.0055\n",
      "Epoch 79/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.7536e-04 - val_loss: 0.0046\n",
      "Epoch 80/80\n",
      "10683/10683 [==============================] - 8s - loss: 2.7519e-04 - val_loss: 0.0059\n",
      "0.0920939573821\n",
      "5.41957239377\n",
      "19.7520836721\n",
      "4.37770892875\n",
      "sequence_testing:9\n",
      "(1096, 5, 4096) (1096, 3, 32, 32, 3) (1096, 3)\n",
      "(10250, 5, 4096) (10250, 3, 32, 32, 3) (10250, 3)\n",
      "Train on 10147 samples, validate on 103 samples\n",
      "Epoch 1/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0277 - val_loss: 0.0149\n",
      "Epoch 2/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 3/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0033 - val_loss: 0.0098\n",
      "Epoch 4/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 5/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 6/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 7/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 8/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0016 - val_loss: 0.0081\n",
      "Epoch 9/80\n",
      "10147/10147 [==============================] - 8s - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 10/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 11/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 12/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 13/80\n",
      "10147/10147 [==============================] - 8s - loss: 0.0010 - val_loss: 0.0097\n",
      "Epoch 14/80\n",
      "10147/10147 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 15/80\n",
      "10147/10147 [==============================] - 7s - loss: 9.6683e-04 - val_loss: 0.0081\n",
      "Epoch 16/80\n",
      "10147/10147 [==============================] - 7s - loss: 9.3094e-04 - val_loss: 0.0037\n",
      "Epoch 17/80\n",
      "10147/10147 [==============================] - 7s - loss: 8.7226e-04 - val_loss: 0.0047\n",
      "Epoch 18/80\n",
      "10147/10147 [==============================] - 7s - loss: 8.3554e-04 - val_loss: 0.0053\n",
      "Epoch 19/80\n",
      "10147/10147 [==============================] - 7s - loss: 8.0932e-04 - val_loss: 0.0029\n",
      "Epoch 20/80\n",
      "10147/10147 [==============================] - 7s - loss: 7.4793e-04 - val_loss: 0.0041\n",
      "Epoch 21/80\n",
      "10147/10147 [==============================] - 7s - loss: 7.4963e-04 - val_loss: 0.0038\n",
      "Epoch 22/80\n",
      "10147/10147 [==============================] - 7s - loss: 7.1647e-04 - val_loss: 0.0057\n",
      "Epoch 23/80\n",
      "10147/10147 [==============================] - 7s - loss: 6.7425e-04 - val_loss: 0.0052\n",
      "Epoch 24/80\n",
      "10147/10147 [==============================] - 7s - loss: 6.4247e-04 - val_loss: 0.0053\n",
      "Epoch 25/80\n",
      "10147/10147 [==============================] - 8s - loss: 6.4308e-04 - val_loss: 0.0074\n",
      "Epoch 26/80\n",
      "10147/10147 [==============================] - 7s - loss: 6.1528e-04 - val_loss: 0.0036\n",
      "Epoch 27/80\n",
      "10147/10147 [==============================] - 7s - loss: 6.0433e-04 - val_loss: 0.0042\n",
      "Epoch 28/80\n",
      "10147/10147 [==============================] - 7s - loss: 5.8904e-04 - val_loss: 0.0042\n",
      "Epoch 29/80\n",
      "10147/10147 [==============================] - 7s - loss: 5.4503e-04 - val_loss: 0.0035\n",
      "Epoch 30/80\n",
      "10147/10147 [==============================] - 7s - loss: 5.5666e-04 - val_loss: 0.0046\n",
      "Epoch 31/80\n",
      "10147/10147 [==============================] - 7s - loss: 5.4309e-04 - val_loss: 0.0056\n",
      "Epoch 32/80\n",
      "10147/10147 [==============================] - 7s - loss: 5.3929e-04 - val_loss: 0.0043\n",
      "Epoch 33/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.9394e-04 - val_loss: 0.0049\n",
      "Epoch 34/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.9798e-04 - val_loss: 0.0028\n",
      "Epoch 35/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.9529e-04 - val_loss: 0.0038\n",
      "Epoch 36/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.7096e-04 - val_loss: 0.0052\n",
      "Epoch 37/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.6639e-04 - val_loss: 0.0036\n",
      "Epoch 38/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.5155e-04 - val_loss: 0.0044\n",
      "Epoch 39/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.3045e-04 - val_loss: 0.0061\n",
      "Epoch 40/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.4345e-04 - val_loss: 0.0035\n",
      "Epoch 41/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.3102e-04 - val_loss: 0.0058\n",
      "Epoch 42/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.2419e-04 - val_loss: 0.0055\n",
      "Epoch 43/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.2165e-04 - val_loss: 0.0053\n",
      "Epoch 44/80\n",
      "10147/10147 [==============================] - 7s - loss: 4.2317e-04 - val_loss: 0.0033\n",
      "Epoch 45/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.9537e-04 - val_loss: 0.0041\n",
      "Epoch 46/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.9665e-04 - val_loss: 0.0045\n",
      "Epoch 47/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.8515e-04 - val_loss: 0.0065\n",
      "Epoch 48/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.7763e-04 - val_loss: 0.0061\n",
      "Epoch 49/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.7447e-04 - val_loss: 0.0065\n",
      "Epoch 50/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.6378e-04 - val_loss: 0.0036\n",
      "Epoch 51/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.5997e-04 - val_loss: 0.0057\n",
      "Epoch 52/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.5300e-04 - val_loss: 0.0063\n",
      "Epoch 53/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.3474e-04 - val_loss: 0.0033\n",
      "Epoch 54/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.4718e-04 - val_loss: 0.0039\n",
      "Epoch 55/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.4558e-04 - val_loss: 0.0058\n",
      "Epoch 56/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.3996e-04 - val_loss: 0.0066\n",
      "Epoch 57/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.4739e-04 - val_loss: 0.0047\n",
      "Epoch 58/80\n",
      "10147/10147 [==============================] - 8s - loss: 3.2570e-04 - val_loss: 0.0064\n",
      "Epoch 59/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.3007e-04 - val_loss: 0.0057\n",
      "Epoch 60/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.1685e-04 - val_loss: 0.0054\n",
      "Epoch 61/80\n",
      "10147/10147 [==============================] - 8s - loss: 3.2481e-04 - val_loss: 0.0054\n",
      "Epoch 62/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.1301e-04 - val_loss: 0.0052\n",
      "Epoch 63/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.0645e-04 - val_loss: 0.0060\n",
      "Epoch 64/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.1112e-04 - val_loss: 0.0069\n",
      "Epoch 65/80\n",
      "10147/10147 [==============================] - 7s - loss: 3.1022e-04 - val_loss: 0.0071\n",
      "Epoch 66/80\n",
      "10147/10147 [==============================] - 8s - loss: 3.0473e-04 - val_loss: 0.0045\n",
      "Epoch 67/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.9485e-04 - val_loss: 0.0056\n",
      "Epoch 68/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.9376e-04 - val_loss: 0.0040\n",
      "Epoch 69/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.9277e-04 - val_loss: 0.0058\n",
      "Epoch 70/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.8879e-04 - val_loss: 0.0045\n",
      "Epoch 71/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.9772e-04 - val_loss: 0.0048\n",
      "Epoch 72/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.8093e-04 - val_loss: 0.0064\n",
      "Epoch 73/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.7593e-04 - val_loss: 0.0057\n",
      "Epoch 74/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.7918e-04 - val_loss: 0.0063\n",
      "Epoch 75/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.7687e-04 - val_loss: 0.0057\n",
      "Epoch 76/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.6596e-04 - val_loss: 0.0053\n",
      "Epoch 77/80\n",
      "10147/10147 [==============================] - 8s - loss: 2.5174e-04 - val_loss: 0.0045\n",
      "Epoch 78/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.6004e-04 - val_loss: 0.0057\n",
      "Epoch 79/80\n",
      "10147/10147 [==============================] - 7s - loss: 2.5593e-04 - val_loss: 0.0043\n",
      "Epoch 80/80\n",
      "10147/10147 [==============================] - 8s - loss: 2.5421e-04 - val_loss: 0.0053\n",
      "0.192126207942\n",
      "5.63688828201\n",
      "20.051608797\n",
      "4.67614073621\n",
      "sequence_testing:10\n",
      "(513, 5, 4096) (513, 3, 32, 32, 3) (513, 3)\n",
      "(10833, 5, 4096) (10833, 3, 32, 32, 3) (10833, 3)\n",
      "Train on 10724 samples, validate on 109 samples\n",
      "Epoch 1/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0271 - val_loss: 0.0168\n",
      "Epoch 2/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0050 - val_loss: 0.0142\n",
      "Epoch 3/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0034 - val_loss: 0.0092\n",
      "Epoch 4/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 5/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0090\n",
      "Epoch 6/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 7/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 8/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 9/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 10/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 11/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0078\n",
      "Epoch 12/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 13/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0077\n",
      "Epoch 14/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 15/80\n",
      "10724/10724 [==============================] - 8s - loss: 0.0010 - val_loss: 0.0077\n",
      "Epoch 16/80\n",
      "10724/10724 [==============================] - 8s - loss: 9.6983e-04 - val_loss: 0.0058\n",
      "Epoch 17/80\n",
      "10724/10724 [==============================] - 8s - loss: 9.4390e-04 - val_loss: 0.0060\n",
      "Epoch 18/80\n",
      "10724/10724 [==============================] - 8s - loss: 8.8510e-04 - val_loss: 0.0069\n",
      "Epoch 19/80\n",
      "10724/10724 [==============================] - 8s - loss: 8.5466e-04 - val_loss: 0.0071\n",
      "Epoch 20/80\n",
      "10724/10724 [==============================] - 8s - loss: 8.0829e-04 - val_loss: 0.0039\n",
      "Epoch 21/80\n",
      "10724/10724 [==============================] - 8s - loss: 7.9725e-04 - val_loss: 0.0057\n",
      "Epoch 22/80\n",
      "10724/10724 [==============================] - 8s - loss: 7.5057e-04 - val_loss: 0.0071\n",
      "Epoch 23/80\n",
      "10724/10724 [==============================] - 8s - loss: 7.3195e-04 - val_loss: 0.0088\n",
      "Epoch 24/80\n",
      "10724/10724 [==============================] - 7s - loss: 7.1047e-04 - val_loss: 0.0055\n",
      "Epoch 25/80\n",
      "10724/10724 [==============================] - 8s - loss: 6.8067e-04 - val_loss: 0.0056\n",
      "Epoch 26/80\n",
      "10724/10724 [==============================] - 8s - loss: 6.9407e-04 - val_loss: 0.0055\n",
      "Epoch 27/80\n",
      "10724/10724 [==============================] - 8s - loss: 6.5262e-04 - val_loss: 0.0064\n",
      "Epoch 28/80\n",
      "10724/10724 [==============================] - 8s - loss: 6.3792e-04 - val_loss: 0.0058\n",
      "Epoch 29/80\n",
      "10724/10724 [==============================] - 8s - loss: 6.1297e-04 - val_loss: 0.0060\n",
      "Epoch 30/80\n",
      "10724/10724 [==============================] - 8s - loss: 6.1924e-04 - val_loss: 0.0061\n",
      "Epoch 31/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.9113e-04 - val_loss: 0.0072\n",
      "Epoch 32/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.9536e-04 - val_loss: 0.0056\n",
      "Epoch 33/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.5466e-04 - val_loss: 0.0068\n",
      "Epoch 34/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.4794e-04 - val_loss: 0.0079\n",
      "Epoch 35/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.3107e-04 - val_loss: 0.0055\n",
      "Epoch 36/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.1933e-04 - val_loss: 0.0079\n",
      "Epoch 37/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.1780e-04 - val_loss: 0.0073\n",
      "Epoch 38/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.9179e-04 - val_loss: 0.0075\n",
      "Epoch 39/80\n",
      "10724/10724 [==============================] - 8s - loss: 5.1533e-04 - val_loss: 0.0066\n",
      "Epoch 40/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.7904e-04 - val_loss: 0.0081\n",
      "Epoch 41/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.7405e-04 - val_loss: 0.0061\n",
      "Epoch 42/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.8628e-04 - val_loss: 0.0086\n",
      "Epoch 43/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.6614e-04 - val_loss: 0.0087\n",
      "Epoch 44/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.5669e-04 - val_loss: 0.0079\n",
      "Epoch 45/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.4933e-04 - val_loss: 0.0059\n",
      "Epoch 46/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.3340e-04 - val_loss: 0.0079\n",
      "Epoch 47/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.4005e-04 - val_loss: 0.0088\n",
      "Epoch 48/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.2244e-04 - val_loss: 0.0064\n",
      "Epoch 49/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.2826e-04 - val_loss: 0.0071\n",
      "Epoch 50/80\n",
      "10724/10724 [==============================] - 8s - loss: 4.3258e-04 - val_loss: 0.0063\n",
      "Epoch 51/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.9769e-04 - val_loss: 0.0067\n",
      "Epoch 52/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.9743e-04 - val_loss: 0.0067\n",
      "Epoch 53/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.8393e-04 - val_loss: 0.0079\n",
      "Epoch 54/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.8470e-04 - val_loss: 0.0079\n",
      "Epoch 55/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.7591e-04 - val_loss: 0.0080\n",
      "Epoch 56/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.7214e-04 - val_loss: 0.0066\n",
      "Epoch 57/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.7405e-04 - val_loss: 0.0083\n",
      "Epoch 58/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.5988e-04 - val_loss: 0.0080\n",
      "Epoch 59/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.6972e-04 - val_loss: 0.0068\n",
      "Epoch 60/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.6398e-04 - val_loss: 0.0074\n",
      "Epoch 61/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.6365e-04 - val_loss: 0.0074\n",
      "Epoch 62/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.5141e-04 - val_loss: 0.0077\n",
      "Epoch 63/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.5422e-04 - val_loss: 0.0067\n",
      "Epoch 64/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.4447e-04 - val_loss: 0.0077\n",
      "Epoch 65/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.3336e-04 - val_loss: 0.0062\n",
      "Epoch 66/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.2523e-04 - val_loss: 0.0064\n",
      "Epoch 67/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.2888e-04 - val_loss: 0.0080\n",
      "Epoch 68/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.3151e-04 - val_loss: 0.0066\n",
      "Epoch 69/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.3018e-04 - val_loss: 0.0076\n",
      "Epoch 70/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.3609e-04 - val_loss: 0.0079\n",
      "Epoch 71/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.2555e-04 - val_loss: 0.0080\n",
      "Epoch 72/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.0943e-04 - val_loss: 0.0065\n",
      "Epoch 73/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.1719e-04 - val_loss: 0.0059\n",
      "Epoch 74/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.1345e-04 - val_loss: 0.0073\n",
      "Epoch 75/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.1790e-04 - val_loss: 0.0075\n",
      "Epoch 76/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.1478e-04 - val_loss: 0.0069\n",
      "Epoch 77/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.0609e-04 - val_loss: 0.0060\n",
      "Epoch 78/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.0879e-04 - val_loss: 0.0069\n",
      "Epoch 79/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.0382e-04 - val_loss: 0.0071\n",
      "Epoch 80/80\n",
      "10724/10724 [==============================] - 8s - loss: 3.0381e-04 - val_loss: 0.0061\n",
      "0.138644567013\n",
      "4.6367854062\n",
      "14.8133522593\n",
      "3.60414355523\n",
      "sequence_testing:11\n",
      "(1312, 5, 4096) (1312, 3, 32, 32, 3) (1312, 3)\n",
      "(10034, 5, 4096) (10034, 3, 32, 32, 3) (10034, 3)\n",
      "Train on 9933 samples, validate on 101 samples\n",
      "Epoch 1/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0283 - val_loss: 0.0025\n",
      "Epoch 2/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0049 - val_loss: 0.0137\n",
      "Epoch 3/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0034 - val_loss: 0.0097\n",
      "Epoch 4/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0028 - val_loss: 0.0104\n",
      "Epoch 5/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 6/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0020 - val_loss: 0.0101\n",
      "Epoch 7/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 8/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 9/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 10/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0090\n",
      "Epoch 11/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 12/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 13/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0075\n",
      "Epoch 14/80\n",
      "9933/9933 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 15/80\n",
      "9933/9933 [==============================] - 7s - loss: 9.8198e-04 - val_loss: 0.0042\n",
      "Epoch 16/80\n",
      "9933/9933 [==============================] - 7s - loss: 8.8947e-04 - val_loss: 0.0021\n",
      "Epoch 17/80\n",
      "9933/9933 [==============================] - 7s - loss: 8.6561e-04 - val_loss: 0.0052\n",
      "Epoch 18/80\n",
      "9933/9933 [==============================] - 7s - loss: 8.4673e-04 - val_loss: 0.0037\n",
      "Epoch 19/80\n",
      "9933/9933 [==============================] - 7s - loss: 7.6940e-04 - val_loss: 0.0068\n",
      "Epoch 20/80\n",
      "9933/9933 [==============================] - 7s - loss: 7.6337e-04 - val_loss: 0.0052\n",
      "Epoch 21/80\n",
      "9933/9933 [==============================] - 7s - loss: 7.1443e-04 - val_loss: 0.0044\n",
      "Epoch 22/80\n",
      "9933/9933 [==============================] - 7s - loss: 6.5530e-04 - val_loss: 0.0035\n",
      "Epoch 23/80\n",
      "9933/9933 [==============================] - 7s - loss: 6.4721e-04 - val_loss: 0.0057\n",
      "Epoch 24/80\n",
      "9933/9933 [==============================] - 7s - loss: 6.3779e-04 - val_loss: 0.0039\n",
      "Epoch 25/80\n",
      "9933/9933 [==============================] - 7s - loss: 6.2255e-04 - val_loss: 0.0071\n",
      "Epoch 26/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.8633e-04 - val_loss: 0.0051\n",
      "Epoch 27/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.8123e-04 - val_loss: 0.0056\n",
      "Epoch 28/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.7048e-04 - val_loss: 0.0069\n",
      "Epoch 29/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.4424e-04 - val_loss: 0.0062\n",
      "Epoch 30/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.1136e-04 - val_loss: 0.0048\n",
      "Epoch 31/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.3237e-04 - val_loss: 0.0068\n",
      "Epoch 32/80\n",
      "9933/9933 [==============================] - 7s - loss: 5.0945e-04 - val_loss: 0.0057\n",
      "Epoch 33/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.9046e-04 - val_loss: 0.0046\n",
      "Epoch 34/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.8819e-04 - val_loss: 0.0054\n",
      "Epoch 35/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.7511e-04 - val_loss: 0.0061\n",
      "Epoch 36/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.6933e-04 - val_loss: 0.0049\n",
      "Epoch 37/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.5464e-04 - val_loss: 0.0051\n",
      "Epoch 38/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.3750e-04 - val_loss: 0.0060\n",
      "Epoch 39/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.3455e-04 - val_loss: 0.0056\n",
      "Epoch 40/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.1294e-04 - val_loss: 0.0049\n",
      "Epoch 41/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.1471e-04 - val_loss: 0.0063\n",
      "Epoch 42/80\n",
      "9933/9933 [==============================] - 7s - loss: 4.0616e-04 - val_loss: 0.0062\n",
      "Epoch 43/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.9619e-04 - val_loss: 0.0069\n",
      "Epoch 44/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.9525e-04 - val_loss: 0.0089\n",
      "Epoch 45/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.9038e-04 - val_loss: 0.0045\n",
      "Epoch 46/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.8128e-04 - val_loss: 0.0047\n",
      "Epoch 47/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.6902e-04 - val_loss: 0.0073\n",
      "Epoch 48/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.5897e-04 - val_loss: 0.0046\n",
      "Epoch 49/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.5577e-04 - val_loss: 0.0075\n",
      "Epoch 50/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.7117e-04 - val_loss: 0.0083\n",
      "Epoch 51/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.4441e-04 - val_loss: 0.0040\n",
      "Epoch 52/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.4267e-04 - val_loss: 0.0078\n",
      "Epoch 53/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.3284e-04 - val_loss: 0.0052\n",
      "Epoch 54/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.3110e-04 - val_loss: 0.0049\n",
      "Epoch 55/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.1956e-04 - val_loss: 0.0076\n",
      "Epoch 56/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.3440e-04 - val_loss: 0.0066\n",
      "Epoch 57/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.2513e-04 - val_loss: 0.0068\n",
      "Epoch 58/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.1399e-04 - val_loss: 0.0055\n",
      "Epoch 59/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.2066e-04 - val_loss: 0.0064\n",
      "Epoch 60/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.1054e-04 - val_loss: 0.0075\n",
      "Epoch 61/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.9976e-04 - val_loss: 0.0060\n",
      "Epoch 62/80\n",
      "9933/9933 [==============================] - 7s - loss: 3.0926e-04 - val_loss: 0.0045\n",
      "Epoch 63/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.9019e-04 - val_loss: 0.0051\n",
      "Epoch 64/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.9477e-04 - val_loss: 0.0045\n",
      "Epoch 65/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.9118e-04 - val_loss: 0.0063\n",
      "Epoch 66/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.8503e-04 - val_loss: 0.0044\n",
      "Epoch 67/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.9136e-04 - val_loss: 0.0072\n",
      "Epoch 68/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.8158e-04 - val_loss: 0.0062\n",
      "Epoch 69/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.7662e-04 - val_loss: 0.0060\n",
      "Epoch 70/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.7432e-04 - val_loss: 0.0061\n",
      "Epoch 71/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.7734e-04 - val_loss: 0.0054\n",
      "Epoch 72/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.8158e-04 - val_loss: 0.0078\n",
      "Epoch 73/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.6741e-04 - val_loss: 0.0061\n",
      "Epoch 74/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.6465e-04 - val_loss: 0.0049\n",
      "Epoch 75/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.6907e-04 - val_loss: 0.0050\n",
      "Epoch 76/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.7018e-04 - val_loss: 0.0054\n",
      "Epoch 77/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.6045e-04 - val_loss: 0.0060\n",
      "Epoch 78/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.6284e-04 - val_loss: 0.0056\n",
      "Epoch 79/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.5668e-04 - val_loss: 0.0060\n",
      "Epoch 80/80\n",
      "9933/9933 [==============================] - 7s - loss: 2.5661e-04 - val_loss: 0.0063\n",
      "0.245192309228\n",
      "6.76742946698\n",
      "21.3815949099\n",
      "6.098863912\n",
      "sequence_testing:12\n",
      "(1197, 5, 4096) (1197, 3, 32, 32, 3) (1197, 3)\n",
      "(10149, 5, 4096) (10149, 3, 32, 32, 3) (10149, 3)\n",
      "Train on 10047 samples, validate on 102 samples\n",
      "Epoch 1/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0286 - val_loss: 0.0116\n",
      "Epoch 2/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 3/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 4/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 5/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0026 - val_loss: 0.0102\n",
      "Epoch 6/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0023 - val_loss: 0.0108\n",
      "Epoch 7/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 8/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 9/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 10/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 11/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 12/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 13/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 14/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 15/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 16/80\n",
      "10047/10047 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0050\n",
      "Epoch 17/80\n",
      "10047/10047 [==============================] - 7s - loss: 9.7182e-04 - val_loss: 0.0068\n",
      "Epoch 18/80\n",
      "10047/10047 [==============================] - 7s - loss: 9.7182e-04 - val_loss: 0.0028\n",
      "Epoch 19/80\n",
      "10047/10047 [==============================] - 7s - loss: 9.1828e-04 - val_loss: 0.0046\n",
      "Epoch 20/80\n",
      "10047/10047 [==============================] - 7s - loss: 8.4008e-04 - val_loss: 0.0032\n",
      "Epoch 21/80\n",
      "10047/10047 [==============================] - 7s - loss: 8.1879e-04 - val_loss: 0.0053\n",
      "Epoch 22/80\n",
      "10047/10047 [==============================] - 7s - loss: 7.7928e-04 - val_loss: 0.0051\n",
      "Epoch 23/80\n",
      "10047/10047 [==============================] - 7s - loss: 7.5252e-04 - val_loss: 0.0054\n",
      "Epoch 24/80\n",
      "10047/10047 [==============================] - 7s - loss: 7.5964e-04 - val_loss: 0.0016\n",
      "Epoch 25/80\n",
      "10047/10047 [==============================] - 7s - loss: 7.0183e-04 - val_loss: 0.0028\n",
      "Epoch 26/80\n",
      "10047/10047 [==============================] - 7s - loss: 6.9895e-04 - val_loss: 0.0063\n",
      "Epoch 27/80\n",
      "10047/10047 [==============================] - 7s - loss: 6.7767e-04 - val_loss: 0.0055\n",
      "Epoch 28/80\n",
      "10047/10047 [==============================] - 7s - loss: 6.4472e-04 - val_loss: 0.0033\n",
      "Epoch 29/80\n",
      "10047/10047 [==============================] - 7s - loss: 6.4543e-04 - val_loss: 0.0029\n",
      "Epoch 30/80\n",
      "10047/10047 [==============================] - 7s - loss: 6.1365e-04 - val_loss: 0.0071\n",
      "Epoch 31/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.9319e-04 - val_loss: 0.0050\n",
      "Epoch 32/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.8878e-04 - val_loss: 0.0032\n",
      "Epoch 33/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.7213e-04 - val_loss: 0.0044\n",
      "Epoch 34/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.7552e-04 - val_loss: 0.0060\n",
      "Epoch 35/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.4702e-04 - val_loss: 0.0057\n",
      "Epoch 36/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.4027e-04 - val_loss: 0.0044\n",
      "Epoch 37/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.2964e-04 - val_loss: 0.0071\n",
      "Epoch 38/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.1360e-04 - val_loss: 0.0060\n",
      "Epoch 39/80\n",
      "10047/10047 [==============================] - 7s - loss: 5.0757e-04 - val_loss: 0.0060\n",
      "Epoch 40/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.8394e-04 - val_loss: 0.0065\n",
      "Epoch 41/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.9628e-04 - val_loss: 0.0060\n",
      "Epoch 42/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.9269e-04 - val_loss: 0.0051\n",
      "Epoch 43/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.6606e-04 - val_loss: 0.0060\n",
      "Epoch 44/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.8133e-04 - val_loss: 0.0047\n",
      "Epoch 45/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.5076e-04 - val_loss: 0.0032\n",
      "Epoch 46/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.3992e-04 - val_loss: 0.0065\n",
      "Epoch 47/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.3524e-04 - val_loss: 0.0050\n",
      "Epoch 48/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.3997e-04 - val_loss: 0.0074\n",
      "Epoch 49/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.1586e-04 - val_loss: 0.0052\n",
      "Epoch 50/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.1769e-04 - val_loss: 0.0044\n",
      "Epoch 51/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.2008e-04 - val_loss: 0.0063\n",
      "Epoch 52/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.0142e-04 - val_loss: 0.0053\n",
      "Epoch 53/80\n",
      "10047/10047 [==============================] - 7s - loss: 4.1180e-04 - val_loss: 0.0062\n",
      "Epoch 54/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.9267e-04 - val_loss: 0.0063\n",
      "Epoch 55/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.9419e-04 - val_loss: 0.0054\n",
      "Epoch 56/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.9187e-04 - val_loss: 0.0059\n",
      "Epoch 57/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.9295e-04 - val_loss: 0.0043\n",
      "Epoch 58/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.8361e-04 - val_loss: 0.0064\n",
      "Epoch 59/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.7937e-04 - val_loss: 0.0051\n",
      "Epoch 60/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.6002e-04 - val_loss: 0.0056\n",
      "Epoch 61/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.8415e-04 - val_loss: 0.0048\n",
      "Epoch 62/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.4876e-04 - val_loss: 0.0036\n",
      "Epoch 63/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.5021e-04 - val_loss: 0.0063\n",
      "Epoch 64/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.4838e-04 - val_loss: 0.0065\n",
      "Epoch 65/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.4402e-04 - val_loss: 0.0066\n",
      "Epoch 66/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.5005e-04 - val_loss: 0.0072\n",
      "Epoch 67/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.4500e-04 - val_loss: 0.0058\n",
      "Epoch 68/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.3362e-04 - val_loss: 0.0051\n",
      "Epoch 69/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.3035e-04 - val_loss: 0.0049\n",
      "Epoch 70/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.2309e-04 - val_loss: 0.0055\n",
      "Epoch 71/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.2337e-04 - val_loss: 0.0066\n",
      "Epoch 72/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.2482e-04 - val_loss: 0.0056\n",
      "Epoch 73/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.3218e-04 - val_loss: 0.0056\n",
      "Epoch 74/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.0987e-04 - val_loss: 0.0052\n",
      "Epoch 75/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.1109e-04 - val_loss: 0.0055\n",
      "Epoch 76/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.1384e-04 - val_loss: 0.0029\n",
      "Epoch 77/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.1446e-04 - val_loss: 0.0057\n",
      "Epoch 78/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.1240e-04 - val_loss: 0.0051\n",
      "Epoch 79/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.0565e-04 - val_loss: 0.0057\n",
      "Epoch 80/80\n",
      "10047/10047 [==============================] - 7s - loss: 3.1514e-04 - val_loss: 0.0059\n",
      "0.095526768427\n",
      "3.04817889078\n",
      "13.6735536194\n",
      "2.31555597709\n",
      "sequence_testing:13\n",
      "(541, 5, 4096) (541, 3, 32, 32, 3) (541, 3)\n",
      "(10805, 5, 4096) (10805, 3, 32, 32, 3) (10805, 3)\n",
      "Train on 10696 samples, validate on 109 samples\n",
      "Epoch 1/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0276 - val_loss: 0.0065\n",
      "Epoch 2/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 3/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 4/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 5/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0024 - val_loss: 0.0079\n",
      "Epoch 6/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 7/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 8/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 9/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 10/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 11/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 12/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 13/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0074\n",
      "Epoch 14/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 15/80\n",
      "10696/10696 [==============================] - 7s - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 16/80\n",
      "10696/10696 [==============================] - 7s - loss: 9.7237e-04 - val_loss: 0.0052\n",
      "Epoch 17/80\n",
      "10696/10696 [==============================] - 7s - loss: 9.2174e-04 - val_loss: 0.0053\n",
      "Epoch 18/80\n",
      "10696/10696 [==============================] - 7s - loss: 8.6521e-04 - val_loss: 0.0039\n",
      "Epoch 19/80\n",
      "10696/10696 [==============================] - 7s - loss: 8.5475e-04 - val_loss: 0.0072\n",
      "Epoch 20/80\n",
      "10696/10696 [==============================] - 8s - loss: 7.8782e-04 - val_loss: 0.0051\n",
      "Epoch 21/80\n",
      "10696/10696 [==============================] - 8s - loss: 7.6805e-04 - val_loss: 0.0063\n",
      "Epoch 22/80\n",
      "10696/10696 [==============================] - 8s - loss: 7.8352e-04 - val_loss: 0.0060\n",
      "Epoch 23/80\n",
      "10696/10696 [==============================] - 8s - loss: 7.3104e-04 - val_loss: 0.0055\n",
      "Epoch 24/80\n",
      "10696/10696 [==============================] - 8s - loss: 6.9590e-04 - val_loss: 0.0053\n",
      "Epoch 25/80\n",
      "10696/10696 [==============================] - 8s - loss: 6.7735e-04 - val_loss: 0.0023\n",
      "Epoch 26/80\n",
      "10696/10696 [==============================] - 8s - loss: 6.8712e-04 - val_loss: 0.0035\n",
      "Epoch 27/80\n",
      "10696/10696 [==============================] - 7s - loss: 6.2455e-04 - val_loss: 0.0038\n",
      "Epoch 28/80\n",
      "10696/10696 [==============================] - 7s - loss: 6.1629e-04 - val_loss: 0.0032\n",
      "Epoch 29/80\n",
      "10696/10696 [==============================] - 7s - loss: 6.0709e-04 - val_loss: 0.0071\n",
      "Epoch 30/80\n",
      "10696/10696 [==============================] - 7s - loss: 6.0895e-04 - val_loss: 0.0039\n",
      "Epoch 31/80\n",
      "10696/10696 [==============================] - 8s - loss: 5.9278e-04 - val_loss: 0.0030\n",
      "Epoch 32/80\n",
      "10696/10696 [==============================] - 7s - loss: 5.5553e-04 - val_loss: 0.0043\n",
      "Epoch 33/80\n",
      "10696/10696 [==============================] - 8s - loss: 5.5329e-04 - val_loss: 0.0054\n",
      "Epoch 34/80\n",
      "10696/10696 [==============================] - 8s - loss: 5.3248e-04 - val_loss: 0.0056\n",
      "Epoch 35/80\n",
      "10696/10696 [==============================] - 8s - loss: 5.2639e-04 - val_loss: 0.0059\n",
      "Epoch 36/80\n",
      "10696/10696 [==============================] - 7s - loss: 5.1659e-04 - val_loss: 0.0034\n",
      "Epoch 37/80\n",
      "10696/10696 [==============================] - 7s - loss: 5.0307e-04 - val_loss: 0.0040\n",
      "Epoch 38/80\n",
      "10696/10696 [==============================] - 7s - loss: 4.9326e-04 - val_loss: 0.0061\n",
      "Epoch 39/80\n",
      "10696/10696 [==============================] - 7s - loss: 5.0146e-04 - val_loss: 0.0051\n",
      "Epoch 40/80\n",
      "10696/10696 [==============================] - 7s - loss: 4.7655e-04 - val_loss: 0.0056\n",
      "Epoch 41/80\n",
      "10696/10696 [==============================] - 7s - loss: 4.7777e-04 - val_loss: 0.0044\n",
      "Epoch 42/80\n",
      "10696/10696 [==============================] - 7s - loss: 4.6275e-04 - val_loss: 0.0054\n",
      "Epoch 43/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.5804e-04 - val_loss: 0.0053\n",
      "Epoch 44/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.3466e-04 - val_loss: 0.0056\n",
      "Epoch 45/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.3551e-04 - val_loss: 0.0034\n",
      "Epoch 46/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.4346e-04 - val_loss: 0.0068\n",
      "Epoch 47/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.2029e-04 - val_loss: 0.0045\n",
      "Epoch 48/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.1657e-04 - val_loss: 0.0050\n",
      "Epoch 49/80\n",
      "10696/10696 [==============================] - 8s - loss: 4.0241e-04 - val_loss: 0.0048\n",
      "Epoch 50/80\n",
      "10696/10696 [==============================] - 7s - loss: 4.1103e-04 - val_loss: 0.0039\n",
      "Epoch 51/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.9361e-04 - val_loss: 0.0063\n",
      "Epoch 52/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.8930e-04 - val_loss: 0.0047\n",
      "Epoch 53/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.8198e-04 - val_loss: 0.0058\n",
      "Epoch 54/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.8440e-04 - val_loss: 0.0049\n",
      "Epoch 55/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.8064e-04 - val_loss: 0.0052\n",
      "Epoch 56/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.5414e-04 - val_loss: 0.0057\n",
      "Epoch 57/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.6265e-04 - val_loss: 0.0042\n",
      "Epoch 58/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.5251e-04 - val_loss: 0.0064\n",
      "Epoch 59/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.5496e-04 - val_loss: 0.0075\n",
      "Epoch 60/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.5662e-04 - val_loss: 0.0060\n",
      "Epoch 61/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.4155e-04 - val_loss: 0.0052\n",
      "Epoch 62/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.3944e-04 - val_loss: 0.0035\n",
      "Epoch 63/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.2833e-04 - val_loss: 0.0055\n",
      "Epoch 64/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.1871e-04 - val_loss: 0.0051\n",
      "Epoch 65/80\n",
      "10696/10696 [==============================] - 8s - loss: 3.3805e-04 - val_loss: 0.0047\n",
      "Epoch 66/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.2510e-04 - val_loss: 0.0057\n",
      "Epoch 67/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.3326e-04 - val_loss: 0.0049\n",
      "Epoch 68/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.2119e-04 - val_loss: 0.0058\n",
      "Epoch 69/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.2092e-04 - val_loss: 0.0063\n",
      "Epoch 70/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.1762e-04 - val_loss: 0.0055\n",
      "Epoch 71/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.1460e-04 - val_loss: 0.0052\n",
      "Epoch 72/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.0655e-04 - val_loss: 0.0052\n",
      "Epoch 73/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.0456e-04 - val_loss: 0.0055\n",
      "Epoch 74/80\n",
      "10696/10696 [==============================] - 7s - loss: 3.0624e-04 - val_loss: 0.0047\n",
      "Epoch 75/80\n",
      "10696/10696 [==============================] - 7s - loss: 2.9440e-04 - val_loss: 0.0046\n",
      "Epoch 76/80\n",
      "10696/10696 [==============================] - 7s - loss: 2.9096e-04 - val_loss: 0.0052\n",
      "Epoch 77/80\n",
      "10696/10696 [==============================] - 7s - loss: 2.9514e-04 - val_loss: 0.0050\n",
      "Epoch 78/80\n",
      "10696/10696 [==============================] - 7s - loss: 2.8907e-04 - val_loss: 0.0049\n",
      "Epoch 79/80\n",
      "10696/10696 [==============================] - 8s - loss: 2.8959e-04 - val_loss: 0.0048\n",
      "Epoch 80/80\n",
      "10696/10696 [==============================] - 7s - loss: 2.8750e-04 - val_loss: 0.0060\n",
      "0.273406494593\n",
      "2.60172845761\n",
      "12.4878552325\n",
      "1.54716861806\n",
      "sequence_testing:14\n",
      "(81, 5, 4096) (81, 3, 32, 32, 3) (81, 3)\n",
      "(11265, 5, 4096) (11265, 3, 32, 32, 3) (11265, 3)\n",
      "Train on 11152 samples, validate on 113 samples\n",
      "Epoch 1/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0263 - val_loss: 0.0049\n",
      "Epoch 2/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 3/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 4/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 5/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 6/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 7/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 8/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 9/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 10/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 11/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 12/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 13/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 14/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 15/80\n",
      "11152/11152 [==============================] - 8s - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 16/80\n",
      "11152/11152 [==============================] - 8s - loss: 9.8685e-04 - val_loss: 0.0030\n",
      "Epoch 17/80\n",
      "11152/11152 [==============================] - 8s - loss: 9.5392e-04 - val_loss: 0.0019\n",
      "Epoch 18/80\n",
      "11152/11152 [==============================] - 8s - loss: 9.0025e-04 - val_loss: 0.0021\n",
      "Epoch 19/80\n",
      "11152/11152 [==============================] - 8s - loss: 8.3636e-04 - val_loss: 0.0019\n",
      "Epoch 20/80\n",
      "11152/11152 [==============================] - 8s - loss: 8.1958e-04 - val_loss: 0.0021\n",
      "Epoch 21/80\n",
      "11152/11152 [==============================] - 8s - loss: 7.9532e-04 - val_loss: 0.0022\n",
      "Epoch 22/80\n",
      "11152/11152 [==============================] - 8s - loss: 7.7254e-04 - val_loss: 0.0021\n",
      "Epoch 23/80\n",
      "11152/11152 [==============================] - 8s - loss: 7.5306e-04 - val_loss: 0.0018\n",
      "Epoch 24/80\n",
      "11152/11152 [==============================] - 8s - loss: 6.9743e-04 - val_loss: 0.0018\n",
      "Epoch 25/80\n",
      "11152/11152 [==============================] - 8s - loss: 7.0397e-04 - val_loss: 0.0019\n",
      "Epoch 26/80\n",
      "11152/11152 [==============================] - 8s - loss: 6.6737e-04 - val_loss: 0.0018\n",
      "Epoch 27/80\n",
      "11152/11152 [==============================] - 8s - loss: 6.4165e-04 - val_loss: 0.0022\n",
      "Epoch 28/80\n",
      "11152/11152 [==============================] - 8s - loss: 6.2400e-04 - val_loss: 0.0018\n",
      "Epoch 29/80\n",
      "11152/11152 [==============================] - 8s - loss: 6.0742e-04 - val_loss: 0.0019\n",
      "Epoch 30/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.8642e-04 - val_loss: 0.0020\n",
      "Epoch 31/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.6889e-04 - val_loss: 0.0025\n",
      "Epoch 32/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.7272e-04 - val_loss: 0.0015\n",
      "Epoch 33/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.5443e-04 - val_loss: 0.0020\n",
      "Epoch 34/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.4124e-04 - val_loss: 0.0022\n",
      "Epoch 35/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.3211e-04 - val_loss: 0.0017\n",
      "Epoch 36/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.2005e-04 - val_loss: 0.0017\n",
      "Epoch 37/80\n",
      "11152/11152 [==============================] - 8s - loss: 5.0448e-04 - val_loss: 0.0014\n",
      "Epoch 38/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.8570e-04 - val_loss: 0.0016\n",
      "Epoch 39/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.7022e-04 - val_loss: 0.0018\n",
      "Epoch 40/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.7575e-04 - val_loss: 0.0017\n",
      "Epoch 41/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.7099e-04 - val_loss: 0.0018\n",
      "Epoch 42/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.5335e-04 - val_loss: 0.0021\n",
      "Epoch 43/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.3632e-04 - val_loss: 0.0023\n",
      "Epoch 44/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.3864e-04 - val_loss: 0.0019\n",
      "Epoch 45/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.3275e-04 - val_loss: 0.0024\n",
      "Epoch 46/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.3192e-04 - val_loss: 0.0022\n",
      "Epoch 47/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.0344e-04 - val_loss: 0.0016\n",
      "Epoch 48/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.1893e-04 - val_loss: 0.0029\n",
      "Epoch 49/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.9566e-04 - val_loss: 0.0019\n",
      "Epoch 50/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.9530e-04 - val_loss: 0.0019\n",
      "Epoch 51/80\n",
      "11152/11152 [==============================] - 8s - loss: 4.0332e-04 - val_loss: 0.0023\n",
      "Epoch 52/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.8432e-04 - val_loss: 0.0017\n",
      "Epoch 53/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.8474e-04 - val_loss: 0.0021\n",
      "Epoch 54/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.8204e-04 - val_loss: 0.0025\n",
      "Epoch 55/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.6481e-04 - val_loss: 0.0013\n",
      "Epoch 56/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.6379e-04 - val_loss: 0.0015\n",
      "Epoch 57/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.6517e-04 - val_loss: 0.0013\n",
      "Epoch 58/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.6222e-04 - val_loss: 0.0016\n",
      "Epoch 59/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.5098e-04 - val_loss: 0.0015\n",
      "Epoch 60/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.3569e-04 - val_loss: 0.0017\n",
      "Epoch 61/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.4685e-04 - val_loss: 0.0026\n",
      "Epoch 62/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.2730e-04 - val_loss: 0.0016\n",
      "Epoch 63/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.3522e-04 - val_loss: 0.0020\n",
      "Epoch 64/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.3234e-04 - val_loss: 0.0017\n",
      "Epoch 65/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.3424e-04 - val_loss: 0.0020\n",
      "Epoch 66/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.1798e-04 - val_loss: 0.0019\n",
      "Epoch 67/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.0939e-04 - val_loss: 0.0019\n",
      "Epoch 68/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.1127e-04 - val_loss: 0.0022\n",
      "Epoch 69/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.0331e-04 - val_loss: 0.0023\n",
      "Epoch 70/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.0930e-04 - val_loss: 0.0025\n",
      "Epoch 71/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.1073e-04 - val_loss: 0.0021\n",
      "Epoch 72/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.0048e-04 - val_loss: 0.0017\n",
      "Epoch 73/80\n",
      "11152/11152 [==============================] - 8s - loss: 3.0528e-04 - val_loss: 0.0028\n",
      "Epoch 74/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.9653e-04 - val_loss: 0.0021\n",
      "Epoch 75/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.9659e-04 - val_loss: 0.0019\n",
      "Epoch 76/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.9964e-04 - val_loss: 0.0019\n",
      "Epoch 77/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.9250e-04 - val_loss: 0.0021\n",
      "Epoch 78/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.7783e-04 - val_loss: 0.0017\n",
      "Epoch 79/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.7930e-04 - val_loss: 0.0022\n",
      "Epoch 80/80\n",
      "11152/11152 [==============================] - 8s - loss: 2.7976e-04 - val_loss: 0.0023\n",
      "2.4949625944\n",
      "6.74511123122\n",
      "10.4261054055\n",
      "6.63947720363\n"
     ]
    }
   ],
   "source": [
    "#training and testing in 15-folds\n",
    "all_angular_error=np.empty(shape=[0])\n",
    "prediction=np.empty(shape=[0,3])\n",
    "time_range=3\n",
    "\n",
    "for testid in range(15):\n",
    "    print 'sequence_testing:%d' % testid\n",
    "    sequence_testing=testid\n",
    "    sequence_training=[i for i in range(15) if i!=sequence_testing]\n",
    "    path_testdata='data_win5/nonlinear_data_fullvideo_%d.npz' % sequence_testing\n",
    "    path_testclass='data_win5/label_fullvideo%d.npz' % sequence_testing\n",
    "    testdata=np.load(path_testdata)['matrix_3d']\n",
    "    testlabel=np.load(path_testclass)['matrix_label']\n",
    "    \n",
    "    indexs_img=matrix_allindex[0,testid]\n",
    "    nb_samples=indexs_img.shape[0]\n",
    "    testdata2= getmimic(indexs_img,time_range,matrix_gt_index,path_sfucolor_all,train_datagen)\n",
    "    print testdata.shape,testdata2.shape,testlabel.shape\n",
    "\n",
    "    \n",
    "    traindata=np.empty(shape=[0,5,4096])\n",
    "    traindata2=np.empty((0,time_range,32,32,3))\n",
    "    trainlabel=np.empty(shape=[0,3])\n",
    "    \n",
    "    for i in sequence_training:\n",
    "        path_data='data_win5/nonlinear_data_fullvideo_%d.npz' % i\n",
    "        path_class='data_win5/label_fullvideo%d.npz' % i\n",
    "        data=np.load(path_data)['matrix_3d']\n",
    "        label=np.load(path_class)['matrix_label']\n",
    "        indexs_img=matrix_allindex[0,i]\n",
    "        data2=getmimic(indexs_img,time_range,matrix_gt_index,path_sfucolor_all,train_datagen)\n",
    "        traindata=np.append(traindata,data,axis=0)\n",
    "        traindata2=np.append(traindata2,data2,axis=0)\n",
    "        trainlabel=np.append(trainlabel,label,axis=0)\n",
    "        \n",
    "        \n",
    "    print traindata.shape,traindata2.shape,trainlabel.shape\n",
    "    \n",
    "\n",
    "    weights_path='data_win5/nonlinear_weights_fullvideo%d' % testid \n",
    "    if os.path.isfile(weights_path):\n",
    "        model.load_weights(weights_path)\n",
    "    else:\n",
    "        model.set_weights(Wsave_initial)\n",
    "        model.fit([traindata2[:,0,:,:,:],traindata2[:,1,:,:,:],traindata2[:,2,:,:,:],traindata], trainlabel, batch_size=128, nb_epoch=80, validation_split=0.01)\n",
    "        model.save_weights(weights_path);\n",
    "        \n",
    "    #load weights, and one more round    \n",
    "    #model.fit([traindata2[:,0,:,:,:],traindata2[:,1,:,:,:],traindata2[:,2,:,:,:],traindata], trainlabel, batch_size=128, nb_epoch=100, validation_split=0.01)\n",
    "    \n",
    "    predicted = model.predict([testdata2[:,0,:,:,:],testdata2[:,1,:,:,:],testdata2[:,2,:,:,:],testdata]) \n",
    "    \n",
    "    all_angular_error=np.append(all_angular_error,get_angular_error(predicted,testlabel),axis=0)\n",
    "    prediction=np.append(prediction,predicted,axis=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-12\n",
      "0.023567917319\n",
      "4.08445709253\n",
      "26.9280602525\n",
      "2.89297087767\n",
      "12.1328887767\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print datetime.date.today()\n",
    "print np.min(all_angular_error)*180/np.pi\n",
    "print np.mean(all_angular_error)*180/np.pi\n",
    "print np.max(all_angular_error)*180/np.pi\n",
    "print np.median(all_angular_error)*180/np.pi\n",
    "p=0.1\n",
    "biggest10_angular_error=np.sort(all_angular_error)[-np.int(all_angular_error.shape[0]*p):-1]\n",
    "print np.mean(biggest10_angular_error)*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0308160107608\n",
      "4.10644882107\n",
      "26.9644969405\n",
      "2.92897245323\n",
      "12.2768034926\n"
     ]
    }
   ],
   "source": [
    "#results reported on paper.\n",
    "print np.min(all_angular_error)*180/np.pi\n",
    "print np.mean(all_angular_error)*180/np.pi\n",
    "print np.max(all_angular_error)*180/np.pi\n",
    "print np.median(all_angular_error)*180/np.pi\n",
    "p=0.1\n",
    "biggest10_angular_error=np.sort(all_angular_error)[-np.int(all_angular_error.shape[0]*p):-1]\n",
    "print np.mean(biggest10_angular_error)*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11346, 3)\n",
      "(11346,)\n"
     ]
    }
   ],
   "source": [
    "rgb_estimate=prediction\n",
    "angular_error=all_angular_error\n",
    "print rgb_estimate.shape\n",
    "print angular_error.shape\n",
    "\n",
    "import scipy.io as sio\n",
    "sio.savemat('results_RCCnet_nonlinear_sfugreyball.mat',mdict={'rgb_estimate': rgb_estimate,'angular_error':angular_error})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
